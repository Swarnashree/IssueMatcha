[{"title":"Unable to fork \/bin\/clang.","body":"**Describe the bug**\r\nWhile I am setting up retina in K8s infra. I am facing below error. \r\n\r\n```ts=2024-03-23T16:55:10.369Z level=debug caller=loader\/compile.go:26 msg=\"Error running command\" goversion=go1.21.8 os=linux arch=arm64 numcores=8 hostname=ip-10-149-82-88.ec2.internal podname=retina-agent-4hldd version=v0.0.1 apiserver=https:\/\/172.20.0.1:443 plugins=packetforward command=\"\/bin\/clang -target bpf -Wall -D__TARGET_ARCH_arm64 -g -O2 -c \/go\/src\/github.com\/microsoft\/retina\/pkg\/plugin\/packetforward\/_cprog\/packetforward.c -o \/go\/src\/github.com\/microsoft\/retina\/pkg\/plugin\/packetforward\/packetforward_bpf.o -I\/go\/src\/github.com\/microsoft\/retina\/pkg\/plugin\/packetforward\/..\/lib\/_arm64 -I\/go\/src\/github.com\/microsoft\/retina\/pkg\/plugin\/packetforward\/..\/lib\/common\/libbpf\/_src\" stderr= error=\"fork\/exec \/bin\/clang: no such file or directory\"\r\nts=2024-03-23T16:55:10.369Z level=info caller=server\/server.go:79 msg=\"gracefully shutting down HTTP server...\" goversion=go1.21.8 os=linux arch=arm64 numcores=8 hostname=ip-10-149-82-88.ec2.internal podname=retina-agent-4hldd version=v0.0.1 apiserver=https:\/\/172.20.0.1:443 plugins=packetforward\r\nts=2024-03-23T16:55:10.369Z level=info caller=server\/server.go:71 msg=\"HTTP server stopped with err: http: Server closed\" goversion=go1.21.8 os=linux arch=arm64 numcores=8 hostname=ip-10-149-82-88.ec2.internal podname=retina-agent-4hldd version=v0.0.1 apiserver=https:\/\/172.20.0.1:443 plugins=packetforward\r\nts=2024-03-23T16:55:10.369Z level=panic caller=controllermanager\/controllermanager.go:118 msg=\"Error running controller manager\" goversion=go1.21.8 os=linux arch=arm64 numcores=8 hostname=ip-10-149-82-88.ec2.internal podname=retina-agent-4hldd version=v0.0.1 apiserver=https:\/\/172.20.0.1:443 plugins=packetforward error=\"failed to reconcile plugin packetforward: fork\/exec \/bin\/clang: no such file or directory\" errorVerbose=\"fork\/exec \/bin\/clang: no such file or directory\\nfailed to reconcile plugin packetforward\\ngithub.com\/microsoft\/retina\/pkg\/managers\/pluginmanager.(*PluginManager).Start\\n\\t\/go\/src\/github.com\/microsoft\/retina\/pkg\/managers\/pluginmanager\/pluginmanager.go:169\\ngithub.com\/microsoft\/retina\/pkg\/managers\/controllermanager.(*Controller).Start.func1\\n\\t\/go\/src\/github.com\/microsoft\/retina\/pkg\/managers\/controllermanager\/controllermanager.go:108\\ngolang.org\/x\/sync\/errgroup.(*Group).Go.func1\\n\\t\/go\/pkg\/mod\/golang.org\/x\/sync@v0.6.0\/errgroup\/errgroup.go:78\\nruntime.goexit\\n\\t\/usr\/local\/go\/src\/runtime\/asm_arm64.s:1197\"\r\npanic: Error running controller manager [recovered]\r\n\tpanic: Error running controller manager\r\n\r\ngoroutine 102 [running]:\r\ngithub.com\/microsoft\/retina\/pkg\/telemetry.TrackPanic()\r\n\t\/go\/src\/github.com\/microsoft\/retina\/pkg\/telemetry\/telemetry.go:112 +0x1e8\r\npanic({0x1eb6b00?, 0x4000334180?})\r\n\t\/usr\/local\/go\/src\/runtime\/panic.go:914 +0x218\r\ngo.uber.org\/zap\/zapcore.CheckWriteAction.OnWrite(0x0?, 0x1?, {0x4000aaace8?, 0x0?, 0x0?})\r\n\t\/go\/pkg\/mod\/go.uber.org\/zap@v1.26.0\/zapcore\/entry.go:196 +0x78\r\ngo.uber.org\/zap\/zapcore.(*CheckedEntry).Write(0x40002341a0, {0x400007ff00, 0x1, 0x1})\r\n\t\/go\/pkg\/mod\/go.uber.org\/zap@v1.26.0\/zapcore\/entry.go:262 +0x2c0\r\ngo.uber.org\/zap.(*Logger).Panic(0x40005f2080?, {0x25cf876?, 0x0?}, {0x400007ff00, 0x1, 0x1})\r\n\t\/go\/pkg\/mod\/go.uber.org\/zap@v1.26.0\/logger.go:284 +0x54\r\ngithub.com\/microsoft\/retina\/pkg\/managers\/controllermanager.(*Controller).Start(0x4000cbf450, {0x298b488?, 0x400046f450?})\r\n\t\/go\/src\/github.com\/microsoft\/retina\/pkg\/managers\/controllermanager\/controllermanager.go:118 +0x22c\r\ncreated by main.main in goroutine 1\r\n\t\/go\/src\/github.com\/microsoft\/retina\/controller\/main.go:286 +0x2190\r\n```\r\n\r\n- OS: AmzonLinux\r\n- Kubernetes Version: 1.28\r\n- Host: EKS\r\n- Retina Version: 1.0.0\r\n\r\nI am not running any operator. for now I am running only DaemonSet and in configmap I am adding plugins \r\n\r\n```\r\nconfig.yaml: |-\r\n    apiServer:\r\n      host: 0.0.0.0\r\n      port: 10093\r\n    logLevel: debug\r\n    enabledPlugin: [\"packetforward\"]\r\n    metricsInterval: 10\r\n    enableTelemetry: false\r\n    enablePodLevel: false\r\n    remoteContext: false\r\n    enableAnnotations: false\r\n```\r\n","comments":["The same thing happening to me as well. \r\n\r\n`\r\n(*Controller).Start.func1\\n\\t\/go\/src\/github.com\/microsoft\/retina\/pkg\/managers\/controllermanager\/controllermanager.go:108\\ngolang.org\/x\/sync\/errgroup.(*Group).Go.func1\\n\\t\/go\/pkg\/mod\/golang.org\/x\/sync@v0.6.0\/errgroup\/errgroup.go:78\\nruntime.goexit\\n\\t\/usr\/local\/go\/src\/runtime\/asm_amd64.s:1650\"\r\npanic: Error running controller manager [recovered]\r\n        panic: Error running controller manager\r\n\r\ngoroutine 16 [running]:\r\ngithub.com\/microsoft\/retina\/pkg\/telemetry.TrackPanic()\r\n        \/go\/src\/github.com\/microsoft\/retina\/pkg\/telemetry\/telemetry.go:112 +0x209\r\npanic({0x242fc60?, 0xc0004241a0?})\r\n        \/usr\/local\/go\/src\/runtime\/panic.go:914 +0x21f\r\ngo.uber.org\/zap\/zapcore.CheckWriteAction.OnWrite(0x1?, 0x0?, {0x0?, 0x0?, 0xc000a6aee0?})\r\n        \/go\/pkg\/mod\/go.uber.org\/zap@v1.26.0\/zapcore\/entry.go:196 +0x54\r\ngo.uber.org\/zap\/zapcore.(*CheckedEntry).Write(0xc0008b6dd0, {0xc00055f740, 0x1, 0x1})\r\n        \/go\/pkg\/mod\/go.uber.org\/zap@v1.26.0\/zapcore\/entry.go:262 +0x3ec\r\ngo.uber.org\/zap.(*Logger).Panic(0xc00055e2c0?, {0x2b48afa?, 0x0?}, {0xc00055f740, 0x1, 0x1})\r\n        \/go\/pkg\/mod\/go.uber.org\/zap@v1.26.0\/logger.go:284 +0x51\r\ngithub.com\/microsoft\/retina\/pkg\/managers\/controllermanager.(*Controller).Start(0xc000a7abe0, {0x2f057d0?, 0xc0006afb30?})\r\n        \/go\/src\/github.com\/microsoft\/retina\/pkg\/managers\/controllermanager\/controllermanager.go:118 +0x28c\r\ncreated by main.main in goroutine 1\r\n        \/go\/src\/github.com\/microsoft\/retina\/controller\/main.go:286 +0x2825\r\n~\/Projects\/retina (main \u2714)\r\n`\r\n\r\nHost: ubuntu 22.04.3\r\nKubernetes Version:  v1.28.6"],"labels":["bug"]},{"title":"can't build binary by `make retina-binary` ","body":"**Describe the bug**\r\n```bash\r\n# make retina-binary\r\npackage command-line-arguments\r\n        imports github.com\/microsoft\/retina\/pkg\/plugin\/packetforward\r\n        imports github.com\/microsoft\/retina\/pkg\/plugin\/packetforward\/_cprog: C source files not allowed when not using cgo or SWIG: packetforward.c\r\npackage command-line-arguments\r\n        imports github.com\/microsoft\/retina\/pkg\/plugin\/packetforward\r\n        imports github.com\/microsoft\/retina\/pkg\/plugin\/packetforward\/_cprog: C source files not allowed when not using cgo or SWIG: packetforward.c\r\nprog.go:12:2: no required module provides package github.com\/golang\/mock\/mockgen\/model: go.mod file not found in current directory or any parent directory; see 'go help modules'\r\nprog.go:14:2: no required module provides package github.com\/microsoft\/retina\/pkg\/plugin\/packetforward: go.mod file not found in current directory or any parent directory; see 'go help modules'\r\n2024\/03\/23 12:35:28 Loading input failed: exit status 1\r\nexit status 1\r\npkg\/plugin\/packetforward\/types_linux.go:31: running \"go\": exit status 1\r\n```\r\n**To Reproduce**\r\nJust run `make retina-binary` on main branch.\r\n\r\n**Expected behavior**\r\nCreate an `output` directory and build retina binary successfully. \r\n\r\n**Screenshots**\r\n\r\n**Platform (please complete the following information):**\r\n\r\n- OS: Ubuntu\r\n- Kubernetes Version: [e.g. 1.22]\r\n- Host: [e.g. AKS, KIND, self-host, etc]\r\n- Retina Version:\r\n\r\n**Additional context**\r\nAdd any other context about the problem here.\r\n","comments":[],"labels":["bug"]},{"title":"feat: publish charts as OCI artifacts to GHCR","body":"Publishes the helm chart to `ghcr.io\/<repo>\/charts\/<chart>:<tag>` on tag.\r\n\r\nSample run: https:\/\/github.com\/rbtr\/retina\/actions\/runs\/8396910644\/job\/22999286123#step:5:9\r\nPublished artifact: https:\/\/github.com\/rbtr\/retina\/pkgs\/container\/retina%2Fcharts%2Fretina\/194747724?tag=v0.0.2","comments":["I came for this !!! I don't want to have to run the make command myself :) Thanks @rbtr "],"labels":["enhancement","area\/infra"]},{"title":"retina-agent pod fails to start HTTP server when running controller manager ","body":"**Describe the bug**\r\nmake helm-install-advanced-remote-context\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n1. Create a default AKS cluster with network monitoring enabled using the [documentation](https:\/\/learn.microsoft.com\/en-us\/azure\/aks\/network-observability-managed-cli?tabs=non-cilium)\r\n2. Download the retina Git repo and run ``` make helm-install-advanced-remote-context``` on the cluster.\r\n3. Retina operator pod works fine.\r\n4. Retina agent pod on all the nodes erroring with the error below:\r\n\r\n```\r\nts=2024-03-22T06:49:25.754Z level=panic caller=controllermanager\/controllermanager.go:118 msg=\"Error running controller manager\" goversion=go1.21.8 os=linux arch=amd64 numcores=2 hostname=aks-nodepool###redacted###003 podname=retina-agent-m2tll version=v0.0.1 apiserver=https:\/\/myakscluster-###redacted###.azmk8s.io:443 plugins=dropreason,packetforward,linuxutil,dns,packetparser error=\"failed to start HTTP server: context canceled\" errorVerbose=\"context canceled\\nfailed to start HTTP server\\ngithub.com\/microsoft\/retina\/pkg\/server.(*Server).Start\\n\\t\/go\/src\/github.com\/microsoft\/retina\/pkg\/server\/server.go:91\\ngithub.com\/microsoft\/retina\/pkg\/managers\/servermanager.(*HTTPServer).Start\\n\\t\/go\/src\/github.com\/microsoft\/retina\/pkg\/managers\/servermanager\/servermanager.go:43\\ngithub.com\/microsoft\/retina\/pkg\/managers\/controllermanager.(*Controller).Start.func2\\n\\t\/go\/src\/github.com\/microsoft\/retina\/pkg\/managers\/controllermanager\/controllermanager.go:111\\ngolang.org\/x\/sync\/errgroup.(*Group).Go.func1\\n\\t\/go\/pkg\/mod\/golang.org\/x\/sync@v0.6.0\/errgroup\/errgroup.go:78\\nruntime.goexit\\n\\t\/usr\/local\/go\/src\/runtime\/asm_amd64.s:1650\"\r\npanic: Error running controller manager [recovered]\r\n        panic: Error running controller manager\r\n\r\ngoroutine 87 [running]:\r\ngithub.com\/microsoft\/retina\/pkg\/telemetry.TrackPanic()\r\n        \/go\/src\/github.com\/microsoft\/retina\/pkg\/telemetry\/telemetry.go:112 +0x209\r\npanic({0x242fc60?, 0xc000d2e6e0?})\r\n        \/usr\/local\/go\/src\/runtime\/panic.go:914 +0x21f\r\ngo.uber.org\/zap\/zapcore.CheckWriteAction.OnWrite(0x1?, 0x0?, {0x0?, 0x0?, 0xc000775540?})\r\n        \/go\/pkg\/mod\/go.uber.org\/zap@v1.26.0\/zapcore\/entry.go:196 +0x54\r\ngo.uber.org\/zap\/zapcore.(*CheckedEntry).Write(0xc0007d3380, {0xc000d40440, 0x1, 0x1})\r\n        \/go\/pkg\/mod\/go.uber.org\/zap@v1.26.0\/zapcore\/entry.go:262 +0x3ec\r\ngo.uber.org\/zap.(*Logger).Panic(0xc000bb91c0?, {0x2b48afa?, 0x0?}, {0xc000d40440, 0x1, 0x1})\r\n        \/go\/pkg\/mod\/go.uber.org\/zap@v1.26.0\/logger.go:284 +0x51\r\ngithub.com\/microsoft\/retina\/pkg\/managers\/controllermanager.(*Controller).Start(0xc000a637c0, {0x2f057d0?, 0xc000447f90?})\r\n        \/go\/src\/github.com\/microsoft\/retina\/pkg\/managers\/controllermanager\/controllermanager.go:118 +0x28c\r\ncreated by main.main in goroutine 1\r\n        \/go\/src\/github.com\/microsoft\/retina\/controller\/main.go:286 +0x2825\r\n```\r\n\r\n**Expected behavior**\r\n1. Retina agent pods should be up and running.\r\n2. adv_network_observability metrics should be available in Grafana\r\n\r\n**Screenshots**\r\nIf applicable, add screenshots to help explain your problem.\r\n\r\n**Platform (please complete the following information):**\r\n\r\n- OS: Ubuntu\r\n- Kubernetes Version: 1.27.9\r\n- Host: [e.g. AKS, KIND, self-host, etc]: AKS\r\n- Retina Version: latest as per doc on retina.sh \r\n\r\n**Additional context**\r\nNA.\r\n","comments":[],"labels":["bug"]},{"title":"retina-agent panics when running locally in a Kind cluster","body":"```\r\nmake helm-install-advanced-local-context\r\n```\r\nLogs:\r\n```\r\nts=2024-03-21T20:58:50.234Z level=panic caller=controllermanager\/controllermanager.go:118 msg=\"Error running controller manager\" goversion=go1.21.8 os=linux arch=amd64 numcores=16 hostname=backstage-worker podname=retina-agent-88dzr version=v0.0.1 apiserver=https:\/\/10.96.0.1:443 plugins=dropreason,packetforward,linuxutil,dns,packetparser error=\"failed to start plugin manager, plugin exited: failed to start plugin packetparser: interface eth0 of type device not found\" errorVerbose=\"interface eth0 of type device not found\\nfailed to start plugin packetparser\\ngithub.com\/microsoft\/retina\/pkg\/managers\/pluginmanager.(*PluginManager).Start.func1\\n\\t\/go\/src\/github.com\/microsoft\/retina\/pkg\/managers\/pluginmanager\/pluginmanager.go:174\\ngolang.org\/x\/sync\/errgroup.(*Group).Go.func1\\n\\t\/go\/pkg\/mod\/golang.org\/x\/sync@v0.6.0\/errgroup\/errgroup.go:78\\nruntime.goexit\\n\\t\/usr\/local\/go\/src\/runtime\/asm_amd64.s:1650\\nfailed to start plugin manager, plugin exited\\ngithub.com\/microsoft\/retina\/pkg\/managers\/pluginmanager.(*PluginManager).Start\\n\\t\/go\/src\/github.com\/microsoft\/retina\/pkg\/managers\/pluginmanager\/pluginmanager.go:186\\ngithub.com\/microsoft\/retina\/pkg\/managers\/controllermanager.(*Controller).Start.func1\\n\\t\/go\/src\/github.com\/microsoft\/retina\/pkg\/managers\/controllermanager\/controllermanager.go:108\\ngolang.org\/x\/sync\/errgroup.(*Group).Go.func1\\n\\t\/go\/pkg\/mod\/golang.org\/x\/sync@v0.6.0\/errgroup\/errgroup.go:78\\nruntime.goexit\\n\\t\/usr\/local\/go\/src\/runtime\/asm_amd64.s:1650\"\r\npanic: Error running controller manager [recovered]\r\n\tpanic: Error running controller manager\r\n\r\ngoroutine 138 [running]:\r\ngithub.com\/microsoft\/retina\/pkg\/telemetry.TrackPanic()\r\n\t\/go\/src\/github.com\/microsoft\/retina\/pkg\/telemetry\/telemetry.go:112 +0x209\r\npanic({0x242fc60?, 0xc003192120?})\r\n\t\/usr\/local\/go\/src\/runtime\/panic.go:914 +0x21f\r\ngo.uber.org\/zap\/zapcore.CheckWriteAction.OnWrite(0x1?, 0x0?, {0x0?, 0x0?, 0xc00318e020?})\r\n\t\/go\/pkg\/mod\/go.uber.org\/zap@v1.26.0\/zapcore\/entry.go:196 +0x54\r\ngo.uber.org\/zap\/zapcore.(*CheckedEntry).Write(0xc0031941a0, {0xc003190380, 0x1, 0x1})\r\n\t\/go\/pkg\/mod\/go.uber.org\/zap@v1.26.0\/zapcore\/entry.go:262 +0x3ec\r\ngo.uber.org\/zap.(*Logger).Panic(0xc000493640?, {0x2b48afa?, 0x0?}, {0xc003190380, 0x1, 0x1})\r\n\t\/go\/pkg\/mod\/go.uber.org\/zap@v1.26.0\/logger.go:284 +0x51\r\ngithub.com\/microsoft\/retina\/pkg\/managers\/controllermanager.(*Controller).Start(0xc000d01cc0, {0x2f057d0?, 0xc000836320?})\r\n\t\/go\/src\/github.com\/microsoft\/retina\/pkg\/managers\/controllermanager\/controllermanager.go:118 +0x28c\r\ncreated by main.main in goroutine 1\r\n\t\/go\/src\/github.com\/microsoft\/retina\/controller\/main.go:286 +0x2825\r\n```","comments":["> ```\r\n> make helm-install-advanced-local-context\r\n> ```\r\n> \r\n> Logs:\r\n> \r\n> ```\r\n> ts=2024-03-21T20:58:50.234Z level=panic caller=controllermanager\/controllermanager.go:118 msg=\"Error running controller manager\" goversion=go1.21.8 os=linux arch=amd64 numcores=16 hostname=backstage-worker podname=retina-agent-88dzr version=v0.0.1 apiserver=https:\/\/10.96.0.1:443 plugins=dropreason,packetforward,linuxutil,dns,packetparser error=\"failed to start plugin manager, plugin exited: failed to start plugin packetparser: interface eth0 of type device not found\" errorVerbose=\"interface eth0 of type device not found\\nfailed to start plugin packetparser\\ngithub.com\/microsoft\/retina\/pkg\/managers\/pluginmanager.(*PluginManager).Start.func1\\n\\t\/go\/src\/github.com\/microsoft\/retina\/pkg\/managers\/pluginmanager\/pluginmanager.go:174\\ngolang.org\/x\/sync\/errgroup.(*Group).Go.func1\\n\\t\/go\/pkg\/mod\/golang.org\/x\/sync@v0.6.0\/errgroup\/errgroup.go:78\\nruntime.goexit\\n\\t\/usr\/local\/go\/src\/runtime\/asm_amd64.s:1650\\nfailed to start plugin manager, plugin exited\\ngithub.com\/microsoft\/retina\/pkg\/managers\/pluginmanager.(*PluginManager).Start\\n\\t\/go\/src\/github.com\/microsoft\/retina\/pkg\/managers\/pluginmanager\/pluginmanager.go:186\\ngithub.com\/microsoft\/retina\/pkg\/managers\/controllermanager.(*Controller).Start.func1\\n\\t\/go\/src\/github.com\/microsoft\/retina\/pkg\/managers\/controllermanager\/controllermanager.go:108\\ngolang.org\/x\/sync\/errgroup.(*Group).Go.func1\\n\\t\/go\/pkg\/mod\/golang.org\/x\/sync@v0.6.0\/errgroup\/errgroup.go:78\\nruntime.goexit\\n\\t\/usr\/local\/go\/src\/runtime\/asm_amd64.s:1650\"\r\n> panic: Error running controller manager [recovered]\r\n> \tpanic: Error running controller manager\r\n> \r\n> goroutine 138 [running]:\r\n> github.com\/microsoft\/retina\/pkg\/telemetry.TrackPanic()\r\n> \t\/go\/src\/github.com\/microsoft\/retina\/pkg\/telemetry\/telemetry.go:112 +0x209\r\n> panic({0x242fc60?, 0xc003192120?})\r\n> \t\/usr\/local\/go\/src\/runtime\/panic.go:914 +0x21f\r\n> go.uber.org\/zap\/zapcore.CheckWriteAction.OnWrite(0x1?, 0x0?, {0x0?, 0x0?, 0xc00318e020?})\r\n> \t\/go\/pkg\/mod\/go.uber.org\/zap@v1.26.0\/zapcore\/entry.go:196 +0x54\r\n> go.uber.org\/zap\/zapcore.(*CheckedEntry).Write(0xc0031941a0, {0xc003190380, 0x1, 0x1})\r\n> \t\/go\/pkg\/mod\/go.uber.org\/zap@v1.26.0\/zapcore\/entry.go:262 +0x3ec\r\n> go.uber.org\/zap.(*Logger).Panic(0xc000493640?, {0x2b48afa?, 0x0?}, {0xc003190380, 0x1, 0x1})\r\n> \t\/go\/pkg\/mod\/go.uber.org\/zap@v1.26.0\/logger.go:284 +0x51\r\n> github.com\/microsoft\/retina\/pkg\/managers\/controllermanager.(*Controller).Start(0xc000d01cc0, {0x2f057d0?, 0xc000836320?})\r\n> \t\/go\/src\/github.com\/microsoft\/retina\/pkg\/managers\/controllermanager\/controllermanager.go:118 +0x28c\r\n> created by main.main in goroutine 1\r\n> \t\/go\/src\/github.com\/microsoft\/retina\/controller\/main.go:286 +0x2825\r\n> ```\r\n\r\nHi @shashankram ,\r\n\r\nAdding some details about the error - the `Packetparser` plugin expects a node to have the `eth0` device to be present and tries to attach `tc` programs to it. \r\n\r\nTwo observations:\r\n1. `Packetparser` shouldn't panic if `eth0` is not present, it should warn and move on. We should definitely fix this in code. Will track the fix using this issue.\r\n2. Even with that fix, Retina may not work as expected on your Kind setup. The plugins are dependent on the underlying host kernel. For example, if the Kind cluster is running on docker installed on a Windows machine, Retina won't run successfully.","For anyone working on this fix, error handling to be done here - https:\/\/github.com\/microsoft\/retina\/blob\/0b8a44caf1fa073cca19649e493b0a66d5416822\/pkg\/plugin\/packetparser\/packetparser_linux.go#L215C3-L215C13","@aman952036"],"labels":["bug","help wanted","area\/ebpf"]},{"title":"fix: Refactor usages of unsafe (microsoft#95)","body":"Addresses issue #95 ","comments":[],"labels":["enhancement","fix"]},{"title":"Distribute kubectl-retina in krew","body":"kubectl-retina is currently distributed as a binary in the release artifacts.\r\nIt would significantly improve the UX to distribute it via Krew.\r\n```[tasklist]\r\n### Tasks\r\n- [ ] https:\/\/github.com\/microsoft\/retina\/pull\/126\r\n```\r\n","comments":["for most complete UX this probably requires that we build kubectl-retina for all supported platforms of kubectl","depends on #100"],"labels":["enhancement","help wanted"]},{"title":"Helm repository for the retina","body":"**Is your feature request related to a problem? Please describe.**\r\nCurrently, setting up installations in a cluster involves several steps to obtain the manifests for the helm. This process includes acquiring various tools locally and executing multiple commands, leading to complexity and potential errors.\r\n\r\n**Describe the solution you'd like**\r\nI envision a straightforward installation process for Retina. Simplifying the setup to just a few steps would greatly enhance user experience.\r\n\r\n**Describe alternatives you've considered**\r\nOne feasible alternative is to establish a dedicated repository for Retina manifests. By adding this repository to Helm, users could easily access and install Retina with minimal effort:\r\n```\r\nhelm repo add retinarepository\r\nhelm install retina\r\n```\r\n\r\n**Additional context**\r\nImplementing this solution could significantly reduce the occurrence of issues that need to be investigated, streamlining the deployment process for Retina.\r\n","comments":["there are some options for how we could handle this:\r\n- use [GH pages](https:\/\/github.com\/vicenteherrera\/github-pages-helm-charts) to host a helm repo (may be challenging, because we use GH pages to host https:\/\/retina.sh)\r\n- use something like [artifacthub](https:\/\/artifacthub.io\/) which natively supports helm charts\r\n- publish [helm charts as OCI](https:\/\/helm.sh\/docs\/topics\/registries\/) artifacts to GHCR\r\n\r\nI favor the last option and it would be straightforward to set up, but interested to see what others think about the UX there, or if there are other options I haven't listed"],"labels":["enhancement","help wanted"]},{"title":"Update drop_reason.c","body":"lenth -> length","comments":["@eltociear please amend your commit message so that it conforms to [Conventional Commits](https:\/\/www.conventionalcommits.org\/en\/v1.0.0\/)\r\n\"fix: typo in drop_reason.c\" or similar is sufficient"],"labels":["documentation","fix"]},{"title":"Duplicate import of flow library","body":"Duplicate import - https:\/\/github.com\/microsoft\/retina\/blob\/debc18823a6535deb9c3d4f6d18dd7aca3c2916c\/pkg\/module\/metrics\/latency.go#L15","comments":[],"labels":["bug","good first issue","help wanted","fix","area\/metrics"]},{"title":"Refactor usages of `unsafe`","body":"There are usages of unsafe which could be made safe\r\nhttps:\/\/github.com\/microsoft\/retina\/blob\/078d15b3612dc2abacd77b01dc9e6413dd3dbb2a\/pkg\/utils\/utils_linux.go#L41\r\n\r\nmay be refactored as\r\n```go\r\nfunc htons(i uint16) uint16 {\r\n  b := make([]byte, 2)\r\n  binary.BigEndian.PutUint16(b, i)\r\n  return binary.BigEndian.Uint16(b)\r\n}\r\n```","comments":["Hi, could you please assign this issue to me?","@Troy-Butler Assigned the issue to you. "],"labels":["help wanted","go"]},{"title":"Dropped flows should identify CPU","body":"**Is your feature request related to a problem? Please describe.**\r\n\r\nRecently, we saw an issue where inside a particular node, packets were dropped on a particular CPU. However, kubectl top was not showing CPU running hot (because only few CPUs out of 32 were over burdened). Add the CPU number to the flow extension for drop.\r\n\r\ncc: @anubhabMajumdar ","comments":[],"labels":["enhancement","area\/plugins","area\/ebpf"]},{"title":"Evaluate security context\/caps ","body":"Retina has CAP_NET_ADMIN, SYS_ADMIN, and others. \r\nEvaluate the caps and make sure we are adding the minimum required permissions","comments":[],"labels":["good first issue","help wanted"]},{"title":"duplicate windows metric: remove `windows_hns_stats`, keep `forward_count`","body":"**Describe the bug**\r\n`networkobservability_windows_hns_stats` is a copy of `networkobservability_forward_count`:\r\nhttps:\/\/github.com\/microsoft\/retina\/blob\/078d15b3612dc2abacd77b01dc9e6413dd3dbb2a\/pkg\/plugin\/windows\/hnsstats\/hnsstats_windows.go#L145\r\n```\r\n# HELP networkobservability_forward_count Total forwarded packets\r\n# TYPE networkobservability_forward_count gauge\r\nnetworkobservability_forward_count{direction=\"egress\"} 176730\r\nnetworkobservability_forward_count{direction=\"ingress\"} 520660\r\n# HELP networkobservability_windows_hns_stats Include many different metrics from packets sent\/received to closed connections\r\n# TYPE networkobservability_windows_hns_stats gauge\r\nnetworkobservability_windows_hns_stats{direction=\"win_packets_recv_count\"} 520660\r\nnetworkobservability_windows_hns_stats{direction=\"win_packets_sent_count\"} 176730\r\n```","comments":["@vakalapa just wanted to confirm here the below metrics need to be removed, correct?\r\nhttps:\/\/github.com\/microsoft\/retina\/blob\/078d15b3612dc2abacd77b01dc9e6413dd3dbb2a\/pkg\/plugin\/windows\/hnsstats\/hnsstats_windows.go#L142-L149","@iamrajhans yes, thanks for looking into this. We will need to verify if the hnscounter stats are being used in the usual forward metrics (both bytes and packet counts) if yes, we are free to delete the duplicate metrics. If not we have to count them in forward metrics. "],"labels":["bug","good first issue","help wanted","area\/metrics","area\/windows"]},{"title":"Add support to track DNS drops","body":"**Is your feature request related to a problem? Please describe.**\r\nWe currently track DNS request\/response. Add support to measure DNS drops as well.\r\n\r\nMaybe:\r\n\r\ncreate new plugin that attaches itself to specific kernel hook points, or\r\nkeep track of DNS requests in user space using TTL cache","comments":[],"labels":["enhancement","help wanted","area\/metrics","area\/plugins"]},{"title":"Fix type\/reason for drop","body":"Fix the type for Drop.\r\nRef:\r\nhttps:\/\/github.com\/microsoft\/retina\/blob\/078d15b3612dc2abacd77b01dc9e6413dd3dbb2a\/pkg\/utils\/flow_utils.go#L106\r\n\r\nAlso, fix the dropreason number - https:\/\/github.com\/cilium\/cilium\/blob\/d13b89dc5d91b674272ded11104372e16fe937aa\/api\/v1\/flow\/flow.pb.go#L430 ","comments":[],"labels":["bug"]},{"title":"Support scheduling distributed captures","body":"**Is your feature request related to a problem? Please describe.**\r\nNetwork issues  is seen during peak hours and doing packet capture at specific time is not easy as at times it is our midnight.\r\nHaving ability to schedule TCP packet capture would be a huge help .\r\n","comments":[],"labels":["enhancement","good first issue","help wanted","area\/captures"]},{"title":"Windows Agent CrashLoopBackOff metricsconfiguration cache sync timeout","body":"### Logs\r\n```\r\n2023-11-01T16:51:15.739Z        info    hnsstats        hnsstats\/hnsstats_windows.go:138        emitting label win_bytes_recv_count for value 866111686\r\n2023-11-01T16:51:25.464Z        fatal   main    controller\/main.go:284  unable to start manager{error 26 0  failed to wait for metricsconfiguration caches to sync: timed out waiting for cache to be synced}\r\n```\r\n\r\n","comments":[],"labels":["bug","help wanted","area\/windows","area\/controllers"]},{"title":"Explore mTLS request observability support","body":"From HN thread:\r\n\r\n> Speaking of observability tools. Anybody here know how to gather more in-depth metrics on mTLS requests? Have an internal (self signed) CA and just want to know which issued certs are presented to nodes. Would be nice to get cert serial number and other metadata as well\r\n\r\nThis is an interesting ask that can help with basic visibility into mTLS issues. Explore how can this be solved and what TLS funcs can be plugged into with eBPF to solve this issue\n```[tasklist]\n### Tasks\n```\n","comments":[],"labels":["enhancement"]},{"title":"Windows has no drops metric for bytes","body":"**Is your feature request related to a problem? Please describe.**\r\nA clear and concise description of what the problem is. \r\n\r\n| Metric | Windows | Linux |\r\n| --- | --- | --- |\r\n| `forward_count` (packets) | \u2714\ufe0f  | \u2714\ufe0f |\r\n| `forward_bytes` | \u2714\ufe0f  | \u2714\ufe0f  |\r\n| `drop_count` (packets) | \u2714\ufe0f  | \u2714\ufe0f |\r\n| `drop_bytes` | \u274c | \u2714\ufe0f  |\r\n\r\nIs it possible to get packet size for drops like we do forwards?\r\nhttps:\/\/github.com\/microsoft\/retina\/blob\/ac26b1d865eff2451eac964b68a7838c31d3b7e8\/pkg\/plugin\/windows\/hnsstats\/hnsstats_windows.go#L142","comments":[],"labels":["enhancement","help wanted","area\/metrics","area\/windows"]},{"title":"API Server Latency buckets are skewed in large scale clusters","body":"**Describe the bug**\r\nA clear and concise description of what the bug is.\r\n\r\nOn this large-scale cluster, all latencies are in the +inf category. Discussed increasing max bucket so that we have better information if latency is larger than 4.5ms (highest bucket currently).\r\n\r\n![image](https:\/\/github.com\/microsoft\/retina\/assets\/9221639\/cafb608e-2a0f-49b1-aafb-99a3d471dcaa)\r\n\r\nDiscussed making bucket width 1ms, starting at 0.5ms so that we don't get a lot of 0ms counts\r\n\r\ncc @huntergregory  @anubhabMajumdar ","comments":["@iamrajhans i see your linked PR, do you want this issue too?","@rbtr yeah"],"labels":["bug","good first issue","help wanted","area\/metrics"]},{"title":"Removing namespace annotation does not remove IP from filtermap.","body":"### Description\r\nWhen removing a namespace annotation, the corresponding IP is not removed from the filtermap, leading to the continuous generation of metrics. \r\n\r\n### Steps to Reproduce\r\n1. Create pods in the namespace.\r\n2. Make sure Retina is installed with enabled pod level and annotations set to true in the config. \r\n3. Annotate the namespace.\r\n4. Generate traffic between pods in ns using something like Kappinger. \r\n5. Confirm that the filtermap is updated and metrics are being generated.\r\n6. Remove the namespace annotation.\r\n7. Check the filtermap. The metrics are still being generated even after removal of the annotation.\r\n\r\n### Expected Behavior\r\nUpon removal of the namespace annotation, the associated IP should be removed from the filtermap, and metrics generation should cease.\r\n\r\n### Actual Behavior\r\nMetrics continue to be generated after removing the namespace annotation. Reconciliation has been observed in the namespace controller, with no apparent errors.\r\n\r\n### Additional Information\r\n\r\nHere is some logs of an automated test. Manual test on single ns or pod should produce same results. \r\n\r\nAnnotated a ns\r\n\r\n`Annotating namespace    {\"namespace\": \"test-drops-annotation-metrics-1696500004\"}`\r\n\r\nConfirmed it was annotated\r\n\r\n\u00a0`Annotated namespaces before removal     {\"annotatedns\": [{\"metadata\":{\"name\":\"test-drops-annotation-metrics-1696500004\",\"uid\":\"643a065c-3915-4b2d-9636-a2e8f624ff6c\",\"resourceVersion\":\"5093791\",\"creationTimestamp\":\"2023-10-06T21:23:08Z\",\"labels\":{\"e2e\":\"true\",\"kubernetes.io\/metadata.name\":\"test-drops-annotation-metrics-1696500004\"},\"annotations\":{\"retina.io\/v1alpha1\":\"observe\"},\"managedFields\":[{\"manager\":\"dropreason.test\",\"operation\":\"Update\",\"apiVersion\":\"v1\",\"time\":\"2023-10-06T21:23:27Z\",\"fieldsType\":\"FieldsV1\",\"fieldsV1\":{\"f:metadata\":{\"f:annotations\":{\".\":{},\"f:retina.io\/v1alpha1\":{}},\"f:labels\":{\".\":{},\"f:e2e\":{},\"f:kubernetes.io\/metadata.name\":{}}}}}]},\"spec\":{\"finalizers\":[\"kubernetes\"]},\"status\":{\"phase\":\"Active\"}}]}`\r\n\r\nRemoved annotation and confirmed it was removed.\r\n\r\n` Annotated namespaces after removal      {\"annotatedns\": null}`\r\n\r\nMetrics still being generated. \r\n`drop packet     {\"labels\": {\"Metric\":\"networkobservability_adv_drop_count\",\"Labels\":[\"direction\",\"egress\",\"reason\",\"IPTABLE_RULE_DROP\",\"ip\",\"\",\"namespace\",\"test-drops-annotation-metrics-\",\"podname\",\"client\",\"workloadKind\",\"\",\"workloadName\",\"\"]}, \"value\": 33}`\r\n\r\n\r\n#### Pod logs\r\n\r\n\r\nAfter removing the namespace, the log from the name reconcile is present showing that the namespace has been removed. \r\n\r\nhttps:\/\/github.com\/microsoft\/retina\/blob\/ac26b1d865eff2451eac964b68a7838c31d3b7e8\/pkg\/controllers\/daemon\/namespace\/namespace_controller.go#L60\r\n\r\n`2023-10-06T21:23:47.630Z        info    NamespaceReconciler     namespace\/namespace_controller.go:60    Namespace does not have annotation      {\"namespace\": \"test-drops-annotation-metrics-1696500004\", \"annotations\": null}`\r\n\r\nmetrics still being generated.\r\n```\r\n2023-10-06T21:23:47.860Z        debug   MetricModule.dropreason-metricsmodule   metrics\/drops.go:160    drop count metric is added in EGRESS in local ctx       {\"labels\": [\"IPTABLE_RULE_DROP\", \"egress\", \"10.224.0.32\", \"test-drops-annotation-metrics-1696500004\", \"client\", \"unknown\", \"unknown\"]}\r\n2023-10-06T21:23:47.860Z        debug   MetricModule.dropreason-metricsmodule   metrics\/drops.go:160    drop count metric is added in EGRESS in local ctx       {\"labels\": [\"IPTABLE_RULE_DROP\", \"egress\", \"10.224.0.32\", \"test-drops-annotation-metrics-1696500004\", \"client\", \"unknown\", \"unknown\"]}\r\n2023-10-06T21:23:47.862Z        debug   MetricModule.dropreason-metricsmodule   metrics\/drops.go:160    drop count metric is added in EGRESS in local ctx       {\"labels\": [\"IPTABLE_RULE_DROP\", \"egress\", \"10.224.0.32\", \"test-drops-annotation-metrics-1696500004\", \"client\", \"unknown\", \"unknown\"]}\r\n```\r\nCache finding pod IP and enriching it\r\n\r\n```\r\n Cache   cache\/cache.go:155      pod found for IP        {\"ip\": \"10.224.0.32\", \"pod Name\": \"test-drops-annotation-metrics-1696500004\/client\"}\r\n2023-10-06T21:23:53.403Z        debug   enricher        enricher\/enricher.go:132        enriched flow   {\"flow\": \"time:{seconds:965422847940441}  verdict:DROPPED  IP:{source:\\\"10.224.0.32\\\"  destination:\\\"10.224.0.62\\\"  ipVersion:IPv4}  l4:{TCP:{source_port:61582  destination_port:20480}}  source:{namespace:\\\"test-drops-annotation-metrics-1696500004\\\"  labels:\\\"pod=client\\\"  pod_name:\\\"client\\\"}  traffic_direction:INGRESS  trace_observation_point:TO_HOST  extensions:{[type.googleapis.com\/utils.RetinaMetadata]:{bytes:60}}\"}\r\n2023-10-06T21:23:53.403Z        debug   MetricModule    metrics\/forward.go:160  forward count metric in EGRESS in local ctx     {\"labels\": [\"egress\", \"10.224.0.32\", \"test-drops-annotation-metrics-1696500004\", \"client\", \"unknown\", \"unknown\"]}\r\n```\r\n\r\ncc: @jimassa  @anubhabMajumdar \r\n","comments":[],"labels":["bug","help wanted","area\/metrics"]},{"title":"Pod level metrics for drop may miss localCtx labels","body":"**Describe the bug**\r\nConsider the following scenario:\r\n\r\nServer is running in a pod on node-1\r\nWe annotate the server to observe dropped packets\r\nApply a network policy for ingress\r\nWhen a pod on other nodes try to connect to server, the IPTABLE rule on that node will drop the packet. However, for local context, our filter_map won't have the IP of the server, hence we will not generate any event. Thus, we will see drop_count increase at the node level, but no pod level labels for the drops\r\nTrue for external connections as well\r\nThis is due to how Azure NPM works today. May need to add disclaimer to account for this behavior.\r\n\r\ncc @anubhabMajumdar \r\n","comments":[],"labels":["bug","area\/metrics","area\/plugins"]},{"title":"remove irrelevant metric labels for dns and apiserver latency","body":"If my understanding is correct, these labels seem irrelevant to these metrics.\r\n\r\n## DNS\r\nSeems like DNS request doesn't need `num_response`, `response`, or `return_code`.\r\n\r\n```\r\nnetworkobservability_dns_request_count{num_response=\"0\",query=\"wpad.svc.cluster.local.\",query_type=\"A\",response=\"\",return_code=\"\"} 354\r\n```\r\n\r\n## API Server Latency\r\n\r\nRemove `count` label from `adv_node_apiserver_no_response`. Only possible time series for this metric right now is:\r\n```\r\nadv_node_apiserver_no_response{count=\"no_response\"}\r\n```\r\n\r\nSee _latency.go_","comments":["@vakalapa can I take this","Sure assigning this to you. Ease feel free to ask any questions you might have. "],"labels":["good first issue","fix"]},{"title":"edge cases for MetricConfiguration CRD","body":"If `enableAnnotations=false`, then advanced metrics won't show up unless a MetricConfiguration CRD exists (metric modules are initialized via metricModule's `Reconcile()`). We should initialize with default context options instead.\r\n\r\nAlso, should we support MetricConfiguration CRD when `enableAnnotations=true`? Right now, we do not:\r\nhttps:\/\/github.com\/microsoft\/retina\/blob\/9248f0d140e5c93da77bdbdf5e43ea3b0029cfd4\/controller\/main.go#L254-L268","comments":[],"labels":["good first issue","fix"]}]