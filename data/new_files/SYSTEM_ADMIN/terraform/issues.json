[{"title":"`terraform fmt` mangles hyphenated-heredoc `error_message`  with newlines embedded in interpolation","body":"### Terraform Version\n\n```shell\nTerraform v1.7.5\r\non linux_amd64\n```\n\n\n### Terraform Configuration Files\n\nThis is a contrived example to show the issue. Each hyphenated heredoc `error_message`  that includes an interpolation which itself is broken over multiple lines results in the indenting of the heredoc and remainder of the enclosing resource being mangled.\r\n\r\n```terraform\r\nvariable \"demo\" {\r\n  type        = list(string)\r\n  default     = [\"a\", \"b\", \"c\"]\r\n  description = \"A list of demo values\"\r\n\r\n  validation {\r\n    condition     = length(var.demo) == 3\r\n    error_message = <<-EOT\r\n      The demo variable must have exactly 3 values, provided values are:\r\n\r\n      ${join(\r\n        \", \",\r\n        formatlist(\"\\\"%s\\\"\", var.demo)\r\n      )}\r\n    EOT\r\n  }\r\n}\r\n\r\ncheck \"demo_values\" {\r\n  assert {\r\n    condition     = length(var.demo) == 3\r\n    error_message = <<-EOT\r\n      The demo variable must have exactly 3 values, provided values are:\r\n\r\n      ${join(\r\n        \", \",\r\n        formatlist(\"\\\"%s\\\"\", var.demo)\r\n      )}\r\n    EOT\r\n  }\r\n}\r\n\r\nresource \"terraform_data\" \"broken\" {\r\n  input = var.demo\r\n\r\n  lifecycle {\r\n    precondition {\r\n      condition     = length(var.demo) == 3\r\n      error_message = <<-EOT\r\n        The demo variable must have exactly 3 values, provided values are:\r\n\r\n        ${join(\r\n          \", \",\r\n          formatlist(\"\\\"%s\\\"\", var.demo)\r\n        )}\r\n      EOT\r\n    }\r\n  }\r\n}\r\n\r\nresource \"terraform_data\" \"working\" {\r\n  input = var.demo\r\n\r\n  lifecycle {\r\n    precondition {\r\n      condition     = length(var.demo) == 3\r\n      error_message = <<-EOT\r\n        The demo variable must have exactly 3 values, provided values are:\r\n\r\n        ${join(\", \", formatlist(\"\\\"%s\\\"\", var.demo))}\r\n      EOT\r\n    }\r\n  }\r\n}\r\n```\r\n\n\n### Debug Output\n\n```sh\r\n> TF_DEBUG=trace terraform fmt 2>&1\r\nmain.tf\r\n```\n\n### Expected Behavior\n\nNo changes to the code.\n\n### Actual Behavior\n\n```terraform\r\nvariable \"demo\" {\r\n  type        = list(string)\r\n  default     = [\"a\", \"b\", \"c\"]\r\n  description = \"A list of demo values\"\r\n\r\n  validation {\r\n    condition = length(var.demo) == 3\r\n    error_message = <<-EOT\r\n      The demo variable must have exactly 3 values, provided values are:\r\n\r\n      ${join(\r\n    \", \",\r\n    formatlist(\"\\\"%s\\\"\", var.demo)\r\n)}\r\n    EOT\r\n}\r\n}\r\n\r\ncheck \"demo_values\" {\r\n  assert {\r\n    condition = length(var.demo) == 3\r\n    error_message = <<-EOT\r\n      The demo variable must have exactly 3 values, provided values are:\r\n\r\n      ${join(\r\n    \", \",\r\n    formatlist(\"\\\"%s\\\"\", var.demo)\r\n)}\r\n    EOT\r\n}\r\n}\r\n\r\nresource \"terraform_data\" \"broken\" {\r\n  input = var.demo\r\n\r\n  lifecycle {\r\n    precondition {\r\n      condition = length(var.demo) == 3\r\n      error_message = <<-EOT\r\n        The demo variable must have exactly 3 values, provided values are:\r\n\r\n        ${join(\r\n      \", \",\r\n      formatlist(\"\\\"%s\\\"\", var.demo)\r\n  )}\r\n      EOT\r\n}\r\n}\r\n}\r\n\r\nresource \"terraform_data\" \"working\" {\r\n  input = var.demo\r\n\r\n  lifecycle {\r\n    precondition {\r\n      condition     = length(var.demo) == 3\r\n      error_message = <<-EOT\r\n        The demo variable must have exactly 3 values, provided values are:\r\n\r\n        ${join(\", \", formatlist(\"\\\"%s\\\"\", var.demo))}\r\n      EOT\r\n    }\r\n  }\r\n}\r\n```\r\n\r\nNotice that `fmt` seems to be treating the blocks with the multiline interpolations as multiline block themselves. This is subtly apparent by the fact that in the `terraform_data.working` resource the `condition` and `error_message` equal sign remains aligned, but on the other examples they do not.\r\n\r\n```terraform\r\n      condition     = length(var.demo) == 3\r\n      error_message = <<-EOT\r\n```\r\n\r\nvs.\r\n\r\n```terraform\r\n    condition = length(var.demo) == 3\r\n    error_message = <<-EOT\r\n```\r\n\r\nAdditionally, the reformatting extends beyond the `EOT` for the heredocs to include the enclosing blocks' braces.\n\n### Steps to Reproduce\n\n1. `terraform fmt`\n\n### Additional Context\n\n_No response_\n\n### References\n\n_No response_","comments":[],"labels":["bug","new"],"number":34877},{"title":"docs: Terraform style guide","body":"**Note:** This PR requires a redirect from the existing style conventions doc. Once this PR is merged, merge https:\/\/github.com\/hashicorp\/terraform-docs-common\/pull\/584\r\n\r\n:mag: [Deploy preview](https:\/\/terraform-fl6xf6kn7-hashicorp.vercel.app\/terraform\/language\/style)\r\n\r\nThe Well-Architected Framework team has gathered feedback from HashiCorp employees and Terraform users in an attempt to build on our recommended style contentions. The intention of this guide is that it is used by those looking to form their own internal standardized style guide.\r\n\r\nThis guide is split into two parts:\r\n\r\n1. Code style: Syntax conventions (brought from the existing style conventions document), resource naming and ordering, linting, variables, outputs, locals, etc.\r\n2. Workflow style: Versioning, repo structure, module design, state management, secrets management, etc\r\n\r\nThis guide is a mix of prescriptive advice and non-prescriptive considerations, as some scenarios truly depend on the situation.","comments":[],"labels":["documentation"],"number":34876},{"title":"Interpolate environment variables when configuring dev_overrides","body":"<!--\r\n\r\nDescribe in detail the changes you are proposing, and the rationale.\r\n\r\nSee the contributing guide:\r\n\r\nhttps:\/\/github.com\/hashicorp\/terraform\/blob\/main\/.github\/CONTRIBUTING.md\r\n\r\n-->\r\n\r\nThis pull request adds environment variable interpolation to the `dev_overrides` configuration block, specifically for the local filesystem path being mapped to the provider source address.\r\n\r\n## Example\r\nBefore the proposed change:\r\n```hcl\r\nprovider_installation {\r\n  dev_overrides {\r\n    \"craigsloggett\/github\" = \"\/Users\/craig.sloggett\/.cache\/go\/bin\"\r\n  }\r\n\r\n  direct {}\r\n}\r\n```\r\nAfter the proposed change:\r\n```hcl\r\nprovider_installation {\r\n  dev_overrides {\r\n    \"craigsloggett\/github\" = \"${GOPATH}\/bin\"\r\n  }\r\n\r\n  direct {}\r\n}\r\n```\r\n\r\n<!--\r\n\r\nLink all GitHub issues fixed by this PR, and add references to prior\r\nrelated PRs.\r\n\r\n-->\r\n\r\nFixes #28602\r\n\r\n## Target Release\r\n\r\n<!--\r\n\r\nIn normal circumstances we only target changes at the upcoming minor\r\nrelease, or as a patch to the current minor version. If you need to\r\nport a security fix to an older release, highlight this here by listing\r\nall targeted releases.\r\n\r\nIf targeting the next patch release, also add the relevant x.y-backport\r\nlabel to enable the backport bot.\r\n\r\n-->\r\n\r\n1.8.x\r\n\r\n## Draft CHANGELOG entry\r\n\r\n<!--\r\n\r\nChoose a category, delete the others:\r\n\r\n-->\r\n\r\n### ENHANCEMENTS\r\n\r\n<!--\r\n\r\nWrite a short description of the user-facing change. Examples:\r\n\r\n- `terraform show -json`: Fixed crash with sensitive set values.\r\n- When rendering a diff, Terraform now quotes the name of any object attribute whose string representation is not a valid identifier.\r\n- The local token configuration in the cloud and remote backend now has higher priority than a token specified in a credentials block in the CLI configuration.\r\n\r\n--> \r\n\r\n-  Maintaining a `terraform.rc` file that's portable across systems, platforms, or users.\r\n","comments":["[![CLA assistant check](https:\/\/cla.hashicorp.com\/pull\/badge\/signed)](https:\/\/cla.hashicorp.com\/hashicorp\/terraform?pullRequest=34873) <br\/>All committers have signed the CLA.","Thanks for this submission! "],"labels":["enhancement"],"number":34873},{"title":"Terraform test expect_failures does not work as expected when type is invalid","body":"### Terraform Version\r\n\r\n```shell\r\nTerraform v1.7.5\r\non darwin_arm64\r\n+ provider registry.terraform.io\/hashicorp\/azurerm v3.96.0\r\n```\r\n\r\n\r\n### Terraform Configuration Files\r\n\r\n# Snippet of test configuration\r\n```terraform\r\n#############################################\r\n# Testing var.rule_collection_group_priority\r\n#############################################\r\n\r\nrun \"invalid_rule_collection_group_priority_low_fails\" {\r\n  command = plan\r\n  expect_failures = [ var.rule_collection_group_priority]\r\n  variables {\r\n    rule_collection_group_priority = 100\r\n  }\r\n}\r\n\r\nrun \"invalid_rule_collection_group_priority_string_fails\" {\r\n  command = plan\r\n  expect_failures = [ var.rule_collection_group_priority]\r\n  variables {\r\n    rule_collection_group_priority = \"invalid\"\r\n  }\r\n}\r\n\r\nrun \"valid_rule_collection_group_priority_succeeds\" {\r\n  command = plan\r\n  variables {\r\n    rule_collection_group_priority = 1000\r\n  }\r\n}\r\n```\r\n\r\n# Snippet of variable definition\r\n```terraform\r\nvariable \"rule_collection_group_priority\" {\r\n  type        = number\r\n  description = \"The rule collection group priority number. This will be provided by the network team.\"\r\n\r\n  validation {\r\n    condition     = var.rule_collection_group_priority >= 1000\r\n    error_message = \"The variable 'rule_collection_group_priority' must be greater than 1000.\"\r\n  }\r\n}\r\n```\r\n\r\n### Debug Output\r\n\r\nnot provided\r\n\r\n### Expected Behavior\r\n\r\nI would expect terraform test to fail on run invalid_rule_collection_group_priority_string_fails.\r\n\r\nWhilst you could argue this is overkill as the type validation already takes care of it, this can be useful to ensure that someone doesn't incorrectly modify a variable and allow an unexpected type.\r\n\r\n### Actual Behavior\r\n\r\nTerraform test errors saying it is missing an expected failure (it definitely is not missing this block)...\r\n\r\n```\r\ntests\/variable_validations.tftest.hcl... in progress\r\n  run \"invalid_project_name_with_space_fails\"... pass\r\n  run \"invalid_project_name_with_underscore_fails\"... pass\r\n  run \"invalid_project_name_empty_fails\"... pass\r\n  run \"valid_project_name_succeeds\"... pass\r\n  run \"invalid_rule_collection_group_priority_low_fails\"... pass\r\n  run \"invalid_rule_collection_group_priority_string_fails\"... fail\r\n\u2577\r\n\u2502 Error: Missing expected failure\r\n\u2502 \r\n\u2502   on tests\/variable_validations.tftest.hcl line 128, in run \"invalid_rule_collection_group_priority_string_fails\":\r\n\u2502  128:   expect_failures = [ var.rule_collection_group_priority]\r\n\u2502 \r\n\u2502 The checkable object, var.rule_collection_group_priority, was expected to report an error but did not.\r\n\u2575\r\n\u2577\r\n\u2502 Error: Invalid value for input variable\r\n\u2502 \r\n\u2502   on tests\/variable_validations.tftest.hcl line 130, in run \"invalid_rule_collection_group_priority_string_fails\":\r\n\u2502  130:     rule_collection_group_priority = \"invalid\"\r\n\u2502 \r\n\u2502 The given value is not suitable for var.rule_collection_group_priority declared at variables.tf:293,1-42: a number is required.\r\n\u2575\r\n  run \"valid_rule_collection_group_priority_succeeds\"... skip\r\ntests\/variable_validations.tftest.hcl... tearing down\r\ntests\/variable_validations.tftest.hcl... fail\r\n```\r\n\r\n### Steps to Reproduce\r\n\r\n1. Create a variable definition as per provided snippet.\r\n2. Create a terraform test file, and add the check below:\r\n\r\n```terraform\r\nrun \"invalid_rule_collection_group_priority_string_fails\" {\r\n  command = plan\r\n  expect_failures = [ var.rule_collection_group_priority]\r\n  variables {\r\n    rule_collection_group_priority = \"invalid\"\r\n  }\r\n}\r\n```\r\n\r\n### Additional Context\r\n\r\n_No response_\r\n\r\n### References\r\n\r\n_No response_","comments":["Hi @mike-guy, thanks for filing this! I've relabelled this as an enhancement request instead of a bug as Terraform is behaving as intended in this case.\r\n\r\nThe intent of the `expect_failures` block is to allow configuration authors to validate the custom conditions they have written within their configuration. As you've mentioned, type errors are validation errors and these are checked separately to the custom conditions that are being checked by the `expect_failures` problem. In this case, the test isn't really running at all but failing with a mechanism similar to a compilation error within a more traditional programming language. You can trust that Terraform itself will prevent your configurations from being planned or applied if the wrong type is supplied, in the same way you don't need to write tests in, for example, go that validate something won't compile if you attempt to supply the wrong type.\r\n\r\n> this can be useful to ensure that someone doesn't incorrectly modify a variable and allow an unexpected type.\r\n\r\nJust a note here, that this would\/should cause a cascade of errors throughout the system. Terraform performs type checking all the way through the configuration. If the type of a variable changed, anywhere that referenced that variable would report an error as the types would no longer match.\r\n\r\nWe can track extending this as you've described as a feature request, but my feeling is that the underlying functionality for validating types is covered by the `terraform validate` command and not something that authors themselves should be validating manually within the tests.\r\n\r\nThanks!","If you are viewing this issue and would like to indicate your interest, please use the \ud83d\udc4d reaction on the issue description to upvote this issue. We also welcome additional use case descriptions. Thanks!"],"labels":["enhancement","new","terraform test"],"number":34871},{"title":"Optional chaining operation","body":"### Terraform Version\n\n```shell\n1.7.2\n```\n\n\n### Use Cases\n\nSuppose I have an optional variable like:\r\n```terraform\r\nvariable \"test\" {\r\n  type = object({\r\n     field1 = string\r\n     # and some other fields\r\n    })\r\n  default = null\r\n)\r\n```\r\n\r\nand then somewhere else I need to use use the value of `var.test.field`, but use a default value of `var.test` is null.\r\n\r\nI would like to be able to do something like:\r\n\r\n```\r\nsomething = coalesce(var.test?.field1, \"default\") # the default may actually depend on other variables\r\n```\r\n\r\n\r\n\r\n\r\n  \n\n### Attempted Solutions\n\nI can of course do something like:\r\n\r\n```terraform\r\nsomething = var.test != null ? var.test.field1 : \"default\"\r\n```\r\n\r\nbut that is awkward and hard to read. It becomes even more so if there are  multiple levels of possibly null objects that need to be traversed, especially since `&&` isn't short circuiting. \r\n\r\nAnother option is to use try:\r\n\r\n```terraform\r\nsomething = try(var.test.field1, \"default\")\r\n```\r\n\r\nthe problem with this is that if I misspell something in `var.test.field1`, it will silently use the default instead of giving me an error. \r\n\r\n\n\n### Proposal\n\nAdd a .? operator similar to [javascript's optional chaining feature](https:\/\/developer.mozilla.org\/en-US\/docs\/Web\/JavaScript\/Reference\/Operators\/Optional_chaining). \r\n\r\nOr maybe add a function like `lookup`, except use the default value if the first argument is null. \r\n\r\nOr have a variant of `try` that will still fail for any other error than trying to look up a field on a null value.\n\n### References\n\n_No response_","comments":["Thanks for this feature request! If you are viewing this issue and would like to indicate your interest, please use the \ud83d\udc4d reaction on the issue description to upvote this issue. We also welcome additional use case descriptions. Thanks again!"],"labels":["enhancement","new"],"number":34870},{"title":"Planned value does not match config value for number","body":"### Terraform Version\n\n```shell\nTerraform v1.8.0-dev\r\non darwin_arm64\r\n\r\nv1.8.0-beta1\n```\n\n\n### Terraform Configuration Files\n\n```terraform\r\nresource \"playground_resource\" \"example\" {\r\n  number_attribute = 9223372036854775808\r\n}\r\n```\r\n\n\n### Debug Output\n\nhttps:\/\/gist.github.com\/bendbennett\/694e16874249f8aaa1a9ab14da84129f\n\n### Expected Behavior\n\nExpecting the plan displayed by the CLI to look as follows:\r\n\r\n```shell\r\nTerraform will perform the following actions:\r\n\r\n  # playground_resource.example will be created\r\n  + resource \"playground_resource\" \"example\" {\r\n      + number_attribute = 9223372036854775808\r\n    }\r\n```\n\n### Actual Behavior\n\nPlan displayed by the CLI looks as follows:\r\n\r\n```shell\r\n  # playground_resource.example will be created\r\n  + resource \"playground_resource\" \"example\" {\r\n      + number_attribute = 9223372036854776000\r\n    }\r\n```\r\n\r\nThe value stored in state matches that from the plan, but differs from that supplied in the configuration:\r\n\r\n```json\r\n{\r\n  \"version\": 4,\r\n  \"terraform_version\": \"1.8.0\",\r\n  \"serial\": 1,\r\n  \"lineage\": \"e3092a01-aadf-643b-a61c-f26cac8e0ca1\",\r\n  \"outputs\": {},\r\n  \"resources\": [\r\n    {\r\n      \"mode\": \"managed\",\r\n      \"type\": \"playground_resource\",\r\n      \"name\": \"example\",\r\n      \"provider\": \"provider[\\\"registry.terraform.io\/bendbennett\/playground\\\"]\",\r\n      \"instances\": [\r\n        {\r\n          \"schema_version\": 0,\r\n          \"attributes\": {\r\n            \"number_attribute\": 9223372036854776000\r\n          },\r\n          \"sensitive_attributes\": []\r\n        }\r\n      ]\r\n    }\r\n  ],\r\n  \"check_results\": null\r\n}\r\n```\n\n### Steps to Reproduce\n\n`terraform apply`\n\n### Additional Context\n\nThis appears to be specific to the value of the integer supplied in the configuration (i.e., 9223372036854775808).\r\n\r\nThe structure of the provider is as follows:\r\n\r\n```go\r\npackage provider\r\n\r\nimport (\r\n\t\"context\"\r\n\r\n\t\"github.com\/hashicorp\/terraform-plugin-framework\/path\"\r\n\t\"github.com\/hashicorp\/terraform-plugin-framework\/resource\"\r\n\t\"github.com\/hashicorp\/terraform-plugin-framework\/resource\/schema\"\r\n\t\"github.com\/hashicorp\/terraform-plugin-framework\/types\"\r\n)\r\n\r\nvar _ resource.Resource = (*playgroundResource)(nil)\r\nvar _ resource.ResourceWithImportState = (*playgroundResource)(nil)\r\n\r\ntype playgroundResource struct {\r\n}\r\n\r\nfunc NewResource() resource.Resource {\r\n\treturn &playgroundResource{}\r\n}\r\n\r\nfunc (e *playgroundResource) Metadata(_ context.Context, req resource.MetadataRequest, resp *resource.MetadataResponse) {\r\n\tresp.TypeName = req.ProviderTypeName + \"_resource\"\r\n}\r\n\r\nfunc (e *playgroundResource) Schema(ctx context.Context, req resource.SchemaRequest, resp *resource.SchemaResponse) {\r\n\tresp.Schema = schema.Schema{\r\n\t\tAttributes: map[string]schema.Attribute{\r\n\t\t\t\"number_attribute\": schema.NumberAttribute{\r\n\t\t\t\tOptional: true,\r\n\t\t\t\tComputed: true,\r\n\t\t\t},\r\n\t\t},\r\n\t}\r\n}\r\n\r\ntype playgroundResourceData struct {\r\n\tNumberAttribute types.Number `tfsdk:\"number_attribute\"`\r\n}\r\n\r\nfunc (e *playgroundResource) Create(ctx context.Context, req resource.CreateRequest, resp *resource.CreateResponse) {\r\n\tvar data playgroundResourceData\r\n\r\n\tdiags := req.Plan.Get(ctx, &data)\r\n\tresp.Diagnostics.Append(diags...)\r\n\r\n\tif resp.Diagnostics.HasError() {\r\n\t\treturn\r\n\t}\r\n\r\n\tdiags = resp.State.Set(ctx, &data)\r\n\tresp.Diagnostics.Append(diags...)\r\n}\r\n\r\nfunc (e *playgroundResource) Read(ctx context.Context, req resource.ReadRequest, resp *resource.ReadResponse) {\r\n\tvar data playgroundResourceData\r\n\r\n\tdiags := req.State.Get(ctx, &data)\r\n\tresp.Diagnostics.Append(diags...)\r\n\r\n\tif resp.Diagnostics.HasError() {\r\n\t\treturn\r\n\t}\r\n\r\n\tdiags = resp.State.Set(ctx, &data)\r\n\tresp.Diagnostics.Append(diags...)\r\n}\r\n\r\nfunc (e *playgroundResource) Update(ctx context.Context, req resource.UpdateRequest, resp *resource.UpdateResponse) {\r\n\tvar data playgroundResourceData\r\n\r\n\tdiags := req.Plan.Get(ctx, &data)\r\n\tresp.Diagnostics.Append(diags...)\r\n\r\n\tif resp.Diagnostics.HasError() {\r\n\t\treturn\r\n\t}\r\n\r\n\tdiags = resp.State.Set(ctx, &data)\r\n\tresp.Diagnostics.Append(diags...)\r\n}\r\n\r\nfunc (e *playgroundResource) Delete(ctx context.Context, req resource.DeleteRequest, resp *resource.DeleteResponse) {\r\n\tvar data playgroundResourceData\r\n\r\n\tdiags := req.State.Get(ctx, &data)\r\n\tresp.Diagnostics.Append(diags...)\r\n\r\n\tif resp.Diagnostics.HasError() {\r\n\t\treturn\r\n\t}\r\n}\r\n\r\nfunc (e *playgroundResource) ImportState(ctx context.Context, req resource.ImportStateRequest, resp *resource.ImportStateResponse) {\r\n\tresource.ImportStatePassthroughID(ctx, path.Root(\"id\"), req, resp)\r\n}\r\n```\r\n\r\nThe `v1.8.0-beta1` version of Terraform appears to be using `github.com\/zclconf\/go-cty v1.14.3` which contains the fix for a previously reported, somewhat similar issue - #34589 \n\n### References\n\n- #34589","comments":["Thanks @bendbennett!\r\n\r\nThis is quite peculiar, because while the plan appears to have stored the truncated value, at least within Terraform alone the final state still ends up with the correct `9223372036854775808`, meaning the problem is entirely within the rendering of the plan to both the CLI and JSON.\r\n\r\nIf your example (which I haven't tried yet) ends up with the incorrect value in state, then there is a separate bug to track down somewhere in the protocol\/framework.","This is also potentially related to https:\/\/github.com\/hashicorp\/terraform\/issues\/34686, which I thought had been fixed. There might have been another rendering path somewhere that has been missed.","Just as little addition here:\r\n\r\n```~\/terraform\/34866 > tf show -json planfile | jq\r\n{\r\n  \"format_version\": \"1.2\",\r\n  \"terraform_version\": \"1.9.0-dev\",\r\n  \"planned_values\": {\r\n    \"root_module\": {\r\n      \"resources\": [\r\n        {\r\n          \"address\": \"tfcoremock_simple_resource.resource\",\r\n          \"mode\": \"managed\",\r\n          \"type\": \"tfcoremock_simple_resource\",\r\n          \"name\": \"resource\",\r\n          \"provider_name\": \"registry.terraform.io\/hashicorp\/tfcoremock\",\r\n          \"schema_version\": 0,\r\n          \"values\": {\r\n            \"bool\": null,\r\n            \"float\": null,\r\n            \"integer\": null,\r\n            \"number\": 9223372036854776000,\r\n            \"string\": null\r\n          },\r\n          \"sensitive_values\": {}\r\n        }\r\n      ]\r\n    }\r\n  },\r\n  \"resource_changes\": [\r\n    {\r\n      \"address\": \"tfcoremock_simple_resource.resource\",\r\n      \"mode\": \"managed\",\r\n      \"type\": \"tfcoremock_simple_resource\",\r\n      \"name\": \"resource\",\r\n      \"provider_name\": \"registry.terraform.io\/hashicorp\/tfcoremock\",\r\n      \"change\": {\r\n        \"actions\": [\r\n          \"create\"\r\n        ],\r\n        \"before\": null,\r\n        \"after\": {\r\n          \"bool\": null,\r\n          \"float\": null,\r\n          \"integer\": null,\r\n          \"number\": 9223372036854776000,\r\n          \"string\": null\r\n        },\r\n        \"after_unknown\": {\r\n          \"id\": true\r\n        },\r\n        \"before_sensitive\": false,\r\n        \"after_sensitive\": {}\r\n      }\r\n    }\r\n  ],\r\n  \"configuration\": {\r\n    \"provider_config\": {\r\n      \"tfcoremock\": {\r\n        \"name\": \"tfcoremock\",\r\n        \"full_name\": \"registry.terraform.io\/hashicorp\/tfcoremock\"\r\n      }\r\n    },\r\n    \"root_module\": {\r\n      \"resources\": [\r\n        {\r\n          \"address\": \"tfcoremock_simple_resource.resource\",\r\n          \"mode\": \"managed\",\r\n          \"type\": \"tfcoremock_simple_resource\",\r\n          \"name\": \"resource\",\r\n          \"provider_config_key\": \"tfcoremock\",\r\n          \"expressions\": {\r\n            \"number\": {\r\n              \"constant_value\": 9223372036854775808\r\n            }\r\n          },\r\n          \"schema_version\": 0\r\n        }\r\n      ]\r\n    }\r\n  },\r\n  \"timestamp\": \"2024-03-20T14:44:45Z\",\r\n  \"applyable\": true,\r\n  \"complete\": true,\r\n  \"errored\": false\r\n}\r\n```\r\n\r\nThe correct value is written within the `configuration` block in the JSON output, but the truncated value within the `resource_changes`.","The problematic number raised here is `2^63`. `(2^63)-1` and `(2^63)+1` are not affected and other numbers close by seem to be unaffected (at least I couldn't find any). But the following are also affected:\r\n\r\n- `2^64`\r\n- `2^65`\r\n- `2^66`\r\n- `2^67`\r\n- `2^68`\r\n\r\nAnd the same pattern seems to continue, with other numbers around those numbers being unaffected and only the exact whole numbers being truncated. I don't have an explanation for this, and I don't think this is in the rendering code of the human-readable plan as this is being printed by the JSON output as well. Very strange.","Also, no number satisfying `x < 2^63` is affected so `2^62` and `2^61` and so on are fine.","These seem like the \"breakpoints\" where the floating point exponent would increase, making the mantissa the same (1) for all of these examples, right?\r\n\r\nSo it seems like what they have in common is that the exponent is >= 63 and the exponent is 1. I don't know what to conclude from that yet, but it is at least an interesting pattern!\r\n","There's still something in `go-cty` or `msgpack` causing this, I've added some test cases to go-cty that demonstrate this. Might be helpful as a starting point for whoever ends up picking this up.","One way we've seen symptoms like this before was accidentally creating a `big.Float` with only 52-bit precision instead of full precision. I think that mainly arose in converting from `float64` to `big.Float`, where unless you override it the precision of the source float is preserved. But I wonder if there's something similar going on when parsing `big.Float` from a string on certain codepaths.\r\n\r\n","I've debugged enough to at least describe the circumstances that cause the bug:\r\n\r\nIf the given number is a whole number that would fit in an int64 then `cty\/msgpack` encodes as the smallest possible MessagePack integer format. MessagePack does not have integer formats greater than signed 64-bit.\r\n\r\nIf the number is too big for an int64 then `cty\/msgpack` then tries to take the `big\/float` as a `float64` and pass _that_ to MessagePack. It's _that_ entry point that causes this bug to happen. It seems that `big.Float.Float64` is indicating that the result has \"exact\" accuracy in that case, which I think makes sense because mantissa 1 and exponent >=63, <2048 can fit into a float64 without loss. The number one less than that would have a mantissa that _doesn't_ fit in a `float64`, and so `cty\/msgpack` would encode it as a string.\r\n\r\nTherefore it seems that the problem is in the round-tripping of some values when they get encoded as `float64`. What I've not determined yet, but intend to determine next, is exactly where the precision is being lost.\r\n","It does indeed seem to be a repeat of the \"`big.Float` with only `float64` precision\" problem. Specifically, `cty.NumberFloat64` constructs a `big.Float` based on a `float64` and doesn't override the precision, so the result has precision 52.\r\n\r\nExplicitly setting the precision to 512 (which is the convention elsewhere in `cty`) makes the string representation the same before and after. Using a smaller precision apparently causes the formatter to do some rounding.\r\n\r\nI'm going to fix this upstream by explicitly setting the precision to 512 before populating the `big.Float` from the `float64`. That should then fix anything that uses `cty.NumberFloatVal`, which includes the MessagePack unmarshaler.\r\n","Actually, I've changed my mind: unilaterally deciding to expand the precision of all numbers when converting to `float64` has some annoying effects on the string representations of _fractional_ numbers that can't be exactly represented in floating point, which I now remember is why this is written the way it is.\r\n\r\nInstead of pretending incoming values are higher precision than they are, we instead expand the precision \"just in time\" during the operations that would benefit from it, so that we're doing _calculations_ with higher precision when needed, but avoid implying in string representations that there's more precision available than was present in the source value.\r\n\r\nI think the most narrow fix here is to avoid using the `float64` encoding for whole numbers even if they can technically fit there, and instead have the encoder use the string representation of any integer that's too big to represent as one of the MessagePack integer encodings. That'll ensure that they get decoded at full precision, because we _do_ always use precision 512 for numbers parsed from strings.\r\n","I've fixed this upstream in cty v1.14.4. The specific commit is https:\/\/github.com\/zclconf\/go-cty\/commit\/f41ae52fdfa8a9590aa00c3ab3ff13cef4dd872f .\r\n\r\nHowever, it's important to note that I fixed this by changing the MessagePack _encoder_ to use a different encoding for large integers. `terraform-plugin-go` has [its own MessagePack implementation that has the same behavior](https:\/\/github.com\/hashicorp\/terraform-plugin-go\/blob\/1d146a83a4bb50a5b96c5f7e0828c6a5d40b1281\/tftypes\/value_msgpack.go#L449-L453), so upgrading `cty` here should fix it in the core-to-provider direction, but will not fix it in the provider-to-core direction.\r\n\r\nI'm not sure which was causing the problem here -- perhaps it's both, since we round-trip through MessagePack in both directions after all -- but either way I would suggest making a similar change to `terraform-plugin-go` so that the treatment of numbers will be the same whichever way they are travelling.\r\n\r\nI'm not going to propose any upgrade change in Terraform yet, because I expect we'll probably want to coordinate the `cty` change and the `terraform-plugin-go` change to release at a similar time so we can minimize the window during which things are inconsistent. If someone else wants to open a PR to upgrade to newer `cty` once we're feeling ready to do it, please go ahead!\r\n","Thank you all for the comprehensive investigation and feedback everyone. Much appreciated.\r\nThanks also for the fix in cty `v1.14.4`.\r\nI've opened an [issue](https:\/\/github.com\/hashicorp\/terraform-plugin-go\/issues\/391) on terraform-plugin-go to track coordination of the change in core and the change that needs to be made to terraform-plugin-go."],"labels":["bug","new"],"number":34866},{"title":"Error when loading plugin schemas outputs diagnostics suffixed with double period","body":"### Terraform Version\r\n\r\n```shell\r\nTerraform v1.8.0-dev\r\non darwin_arm64\r\n\r\nv1.8.0-beta1\r\n```\r\n\r\n\r\n### Terraform Configuration Files\r\n\r\n```terraform\r\nresource \"example_resource\" \"example\" {\r\n  configurable_attribute = provider::example::string_len(\"some-value\")\r\n}\r\n```\r\n\r\n\r\n### Debug Output\r\n\r\nhttps:\/\/gist.github.com\/bendbennett\/6e635384603062b983df30f74b9bbacc\r\n\r\n### Expected Behavior\r\n\r\nExpected the last line of the practitioner-facing error message from the CLI to be suffixed with a single period:\r\n\r\n```shell\r\n\u2502 Function \"string_len\": Parameter at position 0 does not have a name.\r\n```\r\n\r\n### Actual Behavior\r\n\r\nThe last line of the practitioner-facing error message from the CLI is suffixed with a double period:\r\n\r\n```shell\r\n\u2502 Function \"string_len\": Parameter at position 0 does not have a name..\r\n```\r\n\r\n### Steps to Reproduce\r\n\r\n1. `terraform init`\r\n2. `terraform apply`\r\n\r\n### Additional Context\r\n\r\nThis appears to be because the diagnostics are suffixed with a period in two locations:\r\n\r\n- https:\/\/github.com\/hashicorp\/terraform\/blob\/v1.8.0-beta1\/internal\/terraform\/schemas.go#L109\r\n- https:\/\/github.com\/hashicorp\/terraform\/blob\/v1.8.0-beta1\/internal\/terraform\/context.go#L173\r\n\r\n### References\r\n\r\n_No response_","comments":["Hi @bendbennett,\r\n\r\nOur typical convention is that `error.Error()` results should follow the Go convention of _not_ ending with a period, whereas our human-oriented diagnostics are written as full sentences (or paragraphs) and so _do_ use periods to end sentences.\r\n\r\nBecause of that, whenever we're using an `error.Error()` as part of a diagnostic message, we typically add a period after it to translate between the two conventions.\r\n\r\nFrom the locations you linked it seems like this symptom would arise if the `error.Error()` result also had a period, which would be contrary to both our conventions and typical Go idiom. If that's true, I think the fix would be to remove the errant period from the end of the string representation of the error. Is that what's going on here, or did I misunderstand?\r\n","Hi @apparentlymart,\r\n\r\nThanks for looking into this.\r\n\r\nApologies if I've misunderstood. It seems the double period is because the `error` returned by `loadSchemas()` is generated from a call to `diags.Err()`, and the diagnostics  already include a period. So if I'm following your line of reasoning, then perhaps the `error` returned by `diags.Err()` should not contain a suffixed period?","Generating an `error` from a `Diagnostics` and then inserting its string representation into another diagnostic is indeed a situation that can cause this problem. We try to avoid doing that wherever possible -- a diagnostics wrapped in an error should typically be appended directly to another diagnostics, which then automatically unwraps the wrapped diagnostics and appends each of them separately. But if course that can't happen if it's formatted into part of another diagnostic message.\r\n\r\nLooking around at the context near the code snippets you pointed to, I think what we have here is some leftover tech debt from the original shift from using `error` to diagnostics when reporting errors to users. During that transition period we had a lot of APIs that had to still keep returning `error` for a while due to having multiple callsites to update, and so we used this sort of error wrapping and then unwrapping again at the callers that _had_ been updated.\r\n\r\nThere thankfully aren't many example of that left anymore, but this seems like one we missed. The `loadSchemas` function should change to return diagnostics instead of an error, and then the caller should just return those diagnostics directly instead of trying to build its own error diagnostic.\r\n"],"labels":["bug","new"],"number":34865},{"title":"Can not run `terraform console` when I am in the projects directory","body":"### Terraform Version\n\n```shell\nterraform --version\r\nTerraform v1.7.4\r\non darwin_amd64\r\n\r\nYour version of Terraform is out of date! The latest version\r\nis 1.7.5. You can update by downloading from https:\/\/www.terraform.io\/downloads.html\n```\n\n\n### Terraform Configuration Files\n\n```terraform\r\n$ cat main.tf\r\nmodule \"private-cloud\" {\r\n  source                       = \".\/modules\/private-cloud\"\r\n}\r\n```\r\n\n\n### Debug Output\n\n$ terraform console\r\n\u2577\r\n\u2502 Error: Module not installed\r\n\u2502\r\n\u2502   on main.tf line 1:\r\n\u2502    1: module \"private-cloud\" {\r\n\u2502\r\n\u2502 This module is not yet installed. Run \"terraform init\" to install all modules required by this\r\n\u2502 configuration.\r\n\u2575\r\n\n\n### Expected Behavior\n\nNo error should occur\n\n### Actual Behavior\n\nError message returned\n\n### Steps to Reproduce\n\nIf I go into empty directory then `terraform console` works fine.\n\n### Additional Context\n\nI run the command above only to generate couple of UUIDs. I did not expect it to fail.\n\n### References\n\n_No response_","comments":["Hi @EugenKon,\r\n\r\nThe behavior you've described is the intended behavior, because Terraform needs to have this module installed to know what to return if you type `module.private-cloud` into the console. If you run `terraform init` as suggested then that should install the needed dependencies so that the console would work.\r\n\r\nRunning `terraform console` in an empty directory works because Terraform treats that as an entirely empty module that doesn't declare anything and therefore doesn't depend on anything. That's not really an intended way to use Terraform, but it works because a directory without any `.tf` files effectively declares nothing.\r\n\r\nIt seems like this issue is effectively a feature request for some sort of new `terraform console` mode that ignores the configuration completely and only allows evaluating functions with constant values. In other words, to pretend that the current directory is empty even when it isn't. Is that right?\r\n","@apparentlymart You are right. It would be nice to be able to evaluate functions with constant values. \r\n\r\nBased on said, I suggest next: show error message above as is, then show warning message, which will tell to user that he will be able to evaluate function with constant values and then show console like it was shown for empty folder.\r\nThank you.","Thanks for confirming, @EugenKon!\r\n\r\nSo I think the proposal then is: if `terraform console` finds that the configuration is invalid, instead of immediately exiting with an error exit code it could instead behave as if the configuration were totally empty, but still allow evaluating any expression that doesn't refer to something declared in the module.\r\n\r\nAs you note, Terraform should probably generate a warning in that case so that it's clear to the user that the console cannot evaluate anything that refers to objects in the configuration.\r\n\r\n`terraform console` is already able to produce a partial evaluation context when the configuration is statically valid but dynamically incorrect -- it says \"Due to the problems above, some expressions may produce unexpected results.\" and then shows the prompt. The question for this issue is how practical it would be for Terraform to do the same when the configuration can't load at all.\r\n\r\nUnfortunately I think that's not easy because [the configuration gets loaded by the same function that prepares the evaluation context](https:\/\/github.com\/hashicorp\/terraform\/blob\/eecbfbf2cccedfb581469ee63599c4b4abc5c60f\/internal\/command\/console.go#L106-L111), and so it would take at least some refactoring to be able to ask for an evaluation context _without_ loading the configuration.\r\n\r\nI'm going to relabel this as an enhancement to reflect that some further design work is needed to figure out exactly how to solve the problem. In the meantime I suggest using an empty directory -- or, at least, a directory without any `.tf` files -- if you want to evaluate expressions in a constants-only scope.\r\n","@apparentlymart Great! Thank you"],"labels":["enhancement","cli"],"number":34863},{"title":"Proposal for minimizing\/removing secrets from the Terraform state file","body":"# Proposal for minimizing\/removing secrets from the Terraform state file\r\n\r\nWith the additional benefit of low privilege Terraform plans.\r\n\r\n# Background:\r\n\r\nTerraform is a game changer for infrastructure management, the ability to maintain everything as code is a godsend and our entire organization is using it to manage thousands of resources across 10 teams.\r\n\r\nDuring our 3 years of setting up this infrastructure, we've noticed one issue that has been hard to reconcile: The fact that Terraform is \"all powerful\" whilst it is the only acceptable way of changing our infra. These two concepts are constantly at odds with each other. But it doesn't have to be this way.\r\n\r\n`terraform apply` is really the dangerous operation. It affects the infra, it can delete crucial resources, it has \"write\" permissions. `terraform plan` however, does not do anything like that. It just does a bunch of GET requests, compares to the state, and proposes changes, it has \"read\" permissions.\r\n\r\nThis mean `terraform plan` should be runnable by any engineer at our company. They can make changes to the Terraform code on their git branch, run `terraform plan` locally, evaluate their changes, iterate, and eventually create a pull request, that runs another `terraform plan`, to be reviewed by the gatekeepers of our organization. Works great, everyone can develop with velocity, and the security is maintained.\r\n\r\nHowever, its not that simple. There are a few issues that make `terraform plan` nearly as privileged as `terraform apply`. Resources contain secrets in their configurations. These secrets need to be read by `terraform plan` from a datasource API and later during Terraform refresh read again from the resource API for change detection. This means the underlying accounts needs permissions to read secrets from these APIs. Additionally, these secrets are then kept in the Terraform state, which is also readable by `terraform plan`.\r\n\r\nDuring plan we'd want all operations to be as little privileged as possible, this way all engineers can develop and run `terraform plan`` without needing access to any secret values that could be misused for \"write level\" operations later.\r\n\r\n# Proposal\r\n\r\nPlease consider the following proposal for fixing this:\r\n\r\nRead operations defined by the providers could be split between \"plan\" and \"apply\" time reads.\r\n\r\n1. On plan time reads: Resources and datasources would have the option to omit the secrets and return metadata instead which uniquely identifies the secret value\r\n2. On apply time reads: Resources and datasources would return the same data with the secrets included\r\n\r\nThis would require a change in the contract between Terraform and its providers. And 1 change to the way Terraform calls the providers during \"read\" operations.\r\n\r\nBackwards compatibility should be easy enough, if the provider does not define separate plan and apply time read operations, just the plan time read operation would be called.\r\n\r\nThe information returned during the apply time read would have to be consistent with the earlier plan time read. However this should solvable possible in most situations. (eg. Metadata or a unique version identifier). Also there could be a check that all the other fields haven't changed in the meantime.\r\n\r\nThis also means the underlying platforms and APIs should support separate metadata and read permissions. This is already supported by eg Vault and GCP secrets.\r\n\r\n# An example:\r\n\r\nA datasource \"vault_kv_secret_v2\" is used to configure a resource \"google_secret_manager_secret_version\".\r\n\r\nThe 2 read operations will be referred to as \"plan_read\" and \"apply_read\"\r\n\r\nIn this example, both these resources have been updated to use the following endpoints:\r\n\r\n- vault_kv_secret_v2 plan_read: https:\/\/developer.hashicorp.com\/vault\/api-docs\/secret\/kv\/kv-v2#read-secret-metadata\r\n- vault_kv_secret_v2 apply_read: https:\/\/developer.hashicorp.com\/vault\/api-docs\/secret\/kv\/kv-v2#read-secret-version\r\n- google_secret_manager_secret_version plan_read: https:\/\/cloud.google.com\/secret-manager\/docs\/reference\/rest\/v1\/projects.secrets.versions\/list or https:\/\/cloud.google.com\/secret-manager\/docs\/reference\/rest\/v1\/projects.secrets\/get\r\n- google_secret_manager_secret_version apply_read: https:\/\/cloud.google.com\/secret-manager\/docs\/reference\/rest\/v1\/projects.secrets.versions\/get\r\n\r\nCreation Plan (using low privileges):\r\n1. Terraform calls plan_read of vault_kv_secret_v2, which will return only the metadata.\r\n2. Terraform plans a create action and includes it in the `.tfplan`. This will include a reference to vault_kv_secret_v2 and the metadata (no secrets)\r\n\r\nCreation Apply (using higher privileges):\r\n1. Terraform calls apply_read apply_read of vault_kv_secret_v2, which will return the secret data\r\n2. Terraform creates google_secret_manager_secret_version using the metadata\r\n3. The Terraform state is updated with the new resource, which instead of the secret value, contains the metadata returned by the endpoint, as well as a reference to the datasource that is the source for the secret.\r\n4. For the datasource the metadata is also stored.\r\n\r\nUpdate\/Read Plan:\r\n1. Terraform calls plan_read of vault_kv_secret_v2, which will return only the metadata.\r\n2. Terraform calls plan_read of google_secret_manager_secret_version, which will return only the metadata.\r\n3. Terraform compares the metadata of both to the known metadata in the state\r\n4. If the metadata is the same Terraform does nothing with it and continues.\r\n5. If the metadata is different Terraform will include changes for all dependent resources in the state with a value that won't be known until apply.\r\n\r\nUpdate: Apply\r\n1. Terraform calls apply_read apply_read of vault_kv_secret_v2, which will return the secret data\r\n2. Terraform updates google_secret_manager_secret_version using the metadata\r\n3. The state is updated with the new metadata\r\n\r\n# Our current workarounds\r\n\r\n1. We let all applications that can, fetch directly from our vault. This meant Terraform does not need read permissions at all.\r\n2. We set up \"proxy\" serverless functions, that are privileged to read from vault, and configure the secrets in the destination. `terraform apply` has permissions to grant them access to the vault secrets, without having access itself. `terraform plan` only has permissions to view the permissions of the serverless functions, not the secrets themselves.\r\n3. We don't generate secrets with Terraform, or accept the fact they will be visible in the state. We experimented with serverless functions or null_resources to generate these. But this caused issues in the resource dependencies since the secrets aren't available yet at plan.\r\n\r\n# Expansions on the idea\r\n\r\n1. Secret generation currently done by the \"tls\" or \"random\" providers could be done by secret providers such as HashiCorp Vault.\r\n2. Resources that don't support returning the metadata, but don't return the secrets could just be \"assumed\" to not be updated in the background. (depending on provider implementation or lifecycle.ignore_changes)\r\n3. Resources that don't support returning the metadata, and do return the secrets could be \"assumed\" to not update at all (including non-secret fields). This would require Terraform to add a \"refresh=false\" flag to the lifecycle.\r\n\r\n# Additional benefits of apply time and read time fetches:\r\n\r\nAnother issue to setting up lower privileged plans is that provider configurations could depend on a datasource for authentication eg google_service_account_jwt for accessing vault in our GCP pipelines. If these values could update between plan and apply, it could be swapped for a higher privilege token on apply. In addition to the token being fresh.\r\n\r\nhttps:\/\/github.com\/hashicorp\/terraform\/issues\/32100\r\n\r\n# Related issues:\r\n\r\nhttps:\/\/github.com\/hashicorp\/terraform\/issues\/516\r\nhttps:\/\/github.com\/hashicorp\/terraform\/issues\/32100\r\n","comments":["Thanks for this feature request! If you are viewing this issue and would like to indicate your interest, please use the \ud83d\udc4d reaction on the issue description to upvote this issue. We also welcome additional use case descriptions. \r\n\r\nI've sent this to our product manager for review as well. Thanks again!","Thanks for the write-up @rwblokzijl!\r\n\r\nThis sounds more like a proposal to help remove sensitive information from the plan, which is definitely a valid concern. In the current architecture, delaying the read of secrets until apply would still end up with the same data stored in the state. Just to clarify some things here while other research is in progress, points which can't be addressed by these changes alone are as follows:\r\n\r\n - There is not yet a language-level definition for \"secret\", which is something that needs to be codified first. We can't only make use of attributes marked as \"sensitive\", because providers can't account for the change in protocol when they have already defined many sensitive fields. Many existing sensitive fields need to maintain the current workflow to not break their functionality.\r\n - Secrets as commonly conceptualized are often required for managed resources, which must currently store the value in the state regardless of whether it's provided during plan or apply. A new concept for the type and handling of the data would need to be created to prevent this storage (some research has been done in this area already, but it's not easy to fit in the existing language and protocol), or maybe they aren't allowed within managed resources.\r\n - Many examples of providers and resources require their secrets in order to successfully create a plan; delaying the reading of secrets until apply will break these use cases.\r\n - Only removing the secrets sometimes (i.e. making exceptions when they are needed for planning) means they can still appear in the plan. A solution which does not entirely remove secrets from state is not an improvement in security\r\n\r\nThe idea that `apply` is an action which requires elevated privileges is interesting. That might not be a complete solution for the CLI tool on its own, but within a managed workflow it might be part of a larger solution for secrets management."],"labels":["enhancement","new"],"number":34860},{"title":"Fix leakage of sensitive variables on HCL syntax error in variable declaration","body":"# Issue\r\n\r\nIf a .tfvar file contains a syntax error the details are printed regardless of potential sensitivity label.\r\nThis occurs when running terraform apply and\/or plan.\r\n\r\n# Solution\r\n\r\nParse the loaded .tf files, for each variable look up the sensitivity label and create a variable-sensitivity map.\r\nThe diagnostics for the error caused by erronous syntax contains a context telling us which part of the .tfvar file the error belongs to, use this context to map the error to the appropriate variable.\r\nUse the variable name to check sensitivity status from the map we built, and add sensitivity info to the diags ExtraInfo property.\r\n\r\nIn the diagnostics section, before printing, check the ExtraInfo section for a sensitivity label, if present, redact the sensitive information.\r\n\r\n## Before\r\n\r\n```bash\r\n$ .\/terraform plan\r\n\u2577\r\n\u2502 Error: Missing key\/value separator\r\n\u2502\r\n\u2502   on terraform.tfvars line 3:\r\n\u2502    1: secretConfig = { \"something\" = \"extremely confidential\",\r\n\u2502    2:                 \"key\" = \"val\",\r\n\u2502    3:                 \"oops\" }\r\n\u2502\r\n\u2502 Expected an equals sign (\"=\") to mark the beginning of the attribute value.\r\n\u2575\r\n```\r\n\r\n## After\r\n\r\n```bash\r\n$ .\/terraformPatched plan\r\n\u2577\r\n\u2502 Error: Missing key\/value separator\r\n\u2502\r\n\u2502   on terraform.tfvars line 3:\r\n\u2502    1: (SENSITIVE)\r\n\u2502\r\n\u2502 Expected an equals sign (\"=\") to mark the beginning of the attribute value.\r\n\u2575\r\n```\r\n\r\nFixes #31946 \r\n\r\n\r\n### BUG FIXES\r\n\r\n- `terraform plan`: Fixed leakage of sensitive values caused by HCL syntax error in .tfvar file.\r\n- `terraform plan`: Fixed leakage of sensitive values caused by HCL syntax error in .tfvar file.\r\n","comments":["[![CLA assistant check](https:\/\/cla.hashicorp.com\/pull\/badge\/signed)](https:\/\/cla.hashicorp.com\/hashicorp\/terraform?pullRequest=34859) <br\/>All committers have signed the CLA.","Thanks for this submission! I will bring it to triage next week. "],"labels":["bug"],"number":34859}]