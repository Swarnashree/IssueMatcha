[{"title":"Non-literal class parameter types should be deprecated not a warning","body":"## Describe the Bug\r\n\r\nThe [`rake syntax`](https:\/\/github.com\/voxpupuli\/puppet-syntax\/blob\/2c1b8fabd7f384a5cc01255a8c411c665b61704d\/lib\/puppet-syntax\/tasks\/puppet-syntax.rb#L36) task fails when using puppet 7.29.1 or 8.5.1 with non-literal class parameter types. This is because puppet reports the issue as `warning` (in 7.29.1) and `error` (in 8.5.1).\r\n\r\nAdditionally the message `not a Puppet::Pops::Model::AccessExpression` is not helpful.\r\n\r\n## Expected Behavior\r\n\r\nIt should be possible to detect and report on non-literal class parameter types without causing `rake syntax` to fail. The error message should also use the `LabelProvider` to print a meaningful message like:\r\n\r\n> The parameter '$i' must be a literal type, not a '*' expression (line: 1, column: 18) \r\n\r\n## Steps to Reproduce\r\n\r\nGiven a manifest whose class parameter contains an arithmetic expression:\r\n\r\n```puppet\r\nclass foo(Integer[0, 2*2] $i = 0) {}\r\ninclude foo\r\n```\r\n\r\nIn 7.29.1, a warning is generated:\r\n\r\n```\r\n$ bundle exec puppet parser validate classes.pp\r\nWarning: The parameter '$i' must be a literal type, not a Puppet::Pops::Model::AccessExpression (file: \/home\/josh\/work\/puppet\/classes.pp, line: 1, column: 27)\r\n$ echo $?\r\n0\r\n```\r\n\r\nIn 8.5.1, an error is generated:\r\n\r\n```\r\n$ bundle exec puppet parser validate classes.pp\r\nError: Could not parse for environment production: The parameter '$i' must be a literal type, not a Puppet::Pops::Model::AccessExpression (file: \/home\/josh\/work\/puppet\/classes.pp, line: 1, column: 27)\r\n$ echo $?\r\n1\r\n```\r\n\r\nThe `puppet parser valdiate` command is called by the `syntax` rake task and any warnings or greater cause the task to fail in both 7.29.1 and 8.5.1. The `syntax` task is also called by [`rake validate` in puppetlabs_spec_helper](https:\/\/github.com\/puppetlabs\/puppetlabs_spec_helper\/blob\/7863f3f7595fce04d98c8f50a4cdf7a6fbfc1cdf\/lib\/puppetlabs_spec_helper\/rake_tasks.rb#L198).\r\n\r\n## Environment\r\n - Version 7.29.1, 8.5.1\r\n\r\n## Additional Context\r\n\r\nSee https:\/\/github.com\/puppetlabs\/puppet\/pull\/9269","comments":["Migrated issue to [PUP-12026](https:\/\/perforce.atlassian.net\/browse\/PUP-12026)"],"labels":["triaged","bug"],"number":9285},{"title":"Package type should support environment variables","body":"I will just link to the JIRA ticket as this is now a (almost) 10 years old feature request which I'm just mirroring over to the new Github issue tracking process.\r\n\r\nhttps:\/\/puppet.atlassian.net\/browse\/PUP-1526","comments":["Been dying to see this one implemented for soo looong.","The original request was to support situations like:\r\n\r\n```\r\n# This is needed for removing the sudo package since it won't uninstall\r\n# when there is no root password set or $SUDO_FORCE_REMOVE != yes\r\nexec { '\/usr\/bin\/apt-get --force-yes --assume-yes install sudo-ldap':\r\n    environment => 'SUDO_FORCE_REMOVE=yes',\r\n    unless      => '\/usr\/bin\/dpkg -l sudo-ldap|tail -1|grep \"^ii\"'\r\n}\r\n```\r\n\r\nAn earlier attempt was made in https:\/\/github.com\/puppetlabs\/puppet\/pull\/4928, but that was closed due to inactivity.\r\n\r\nTo add this capability, an `environment` parameter needs to be added to `Puppet::Type::Package`, similar to how this is done for `Puppet::Type::Exec`\r\n\r\nhttps:\/\/github.com\/puppetlabs\/puppet\/blob\/57a00cc5c5a09469e95945c248ed9ccd2117a01e\/lib\/puppet\/type\/exec.rb#L300\r\n\r\nIf an `environment` parameter is specified on a package resource, then the package providers should pass the parameter into the `Puppet::Util::Execution.execute` method as a `custom_environment`\r\n\r\nhttps:\/\/github.com\/puppetlabs\/puppet\/blob\/57a00cc5c5a09469e95945c248ed9ccd2117a01e\/lib\/puppet\/util\/execution.rb#L149\r\n\r\nSimilarly for calls to `execpipe` like https:\/\/github.com\/puppetlabs\/puppet\/blob\/57a00cc5c5a09469e95945c248ed9ccd2117a01e\/lib\/puppet\/provider\/package\/dpkg.rb#L24\r\n\r\nWe also need to account for the `has_command` DSL method, which providers use to resolve commands like:\r\n\r\nhttps:\/\/github.com\/puppetlabs\/puppet\/blob\/57a00cc5c5a09469e95945c248ed9ccd2117a01e\/lib\/puppet\/provider\/package\/yum.rb#L25\r\n\r\nI started hacking on this here https:\/\/github.com\/puppetlabs\/puppet\/compare\/main...joshcooper:puppet:package_environment?expand=1","Do you estimate this will be released in the next minor puppet release?","> Do you estimate this will be released in the next minor puppet release?\r\n\r\nSorry no, no idea. The branch above is just to explore different options and see how this might be implemented."],"labels":["enhancement","accepted"],"number":9264},{"title":"Provide an option to disable catalog messages","body":"## Use Case\r\nWe recently added \"notice\" level messages specifying the server that the agent is requesting a catalog from and the server that actually handled the request, e.g. `Notice: Requesting catalog from puppet.example.com:8140.` See https:\/\/github.com\/puppetlabs\/puppet\/pull\/9126\r\n\r\nAs described in https:\/\/github.com\/puppetlabs\/puppet\/issues\/9223, the agent may hang for 2 minutes trying to resolve the DNS name into an IPv6 address. Other users have reported not wanting these messages to be printed (or at least not at the `Notice` level).\r\n\r\n## Describe the Solution You Would Like\r\n\r\nAdd a boolean puppet setting to allow the DNS resolution to be disabled. It should be enabled by default.\r\n\r\n## Describe Alternatives You've Considered\r\n\r\nCreating an enum to allow the behavior to be disabled or logged at a different verbosity level.\r\n\r\n## Additional Context\r\n\r\nhttps:\/\/puppetcommunity.slack.com\/archives\/C0W298S9G\/p1706879255760149\r\nhttps:\/\/puppetcommunity.slack.com\/archives\/C0W298S9G\/p1705964713457719\r\n\r\n","comments":["Migrated issue to [PUP-12023](https:\/\/perforce.atlassian.net\/browse\/PUP-12023)"],"labels":["triaged","enhancement"],"number":9262},{"title":"Improve error handling when catalog contains binary data","body":"## Describe the Bug\r\n\r\nIf you accidentally include binary data in the catalog, then the problem is difficult to troubleshoot as the error doesn't specify which environment\/module\/resource\/parameter is causing the issue.\r\n\r\nPuppetserver 8 will fail compilation and its log will contain:\r\n\r\n```\r\n2024-02-14T20:26:59.001Z ERROR [qtp1784649573-50] [puppetserver] Puppet Server Error: Failed to serialize Puppet::Resource::Catalog for 'XXX': Could not render to Puppet::Network::Format[rich_data_json]: source sequence is illegal\/malformed utf-8\r\n```\r\nwhich is surfaced on the agent as:\r\n\r\n```\r\nError: Could not retrieve catalog from remote server: Error 500 on SERVER: Server Error: Failed to serialize ...\r\n```\r\n\r\nIn puppet7, puppetserver will silently downgrade to PSON (though this can be disabled with `allow_pson_serialization` setting). The agent will deserialize the catalog as PSON, and then report a warning when trying to cache the catalog as JSON:\r\n\r\n```\r\n# puppet agent -t\r\n...\r\nInfo: Unable to serialize catalog to json, retrying with pson. PSON is deprecated and will be removed in a future release\r\n```\r\n\r\nThere are two variations to this problem. First, the string needs to be UTF-8 encoded, so `String#encoding` should return `UTF-8` and not `ASCII_8BIT` (aka `BINARY`). Second, the string needs to be valid UTF-8, so `String.valid_encoding?` must be true. The latter case, can easily occur when using the `file` function instead of `binary_file`.\r\n\r\n## Expected Behavior\r\n\r\nIf binary data is accidentally introduced into the catalog and is not wrapped in `Binary`, as can occur when using the `file` function, then the compilation should fail indicating which resource caused the issue.\r\n\r\n## Steps to Reproduce\r\nSteps to reproduce the behavior:\r\n\r\n1. On puppetserver, run this script:\r\n\r\n```ruby\r\nbinary_content = \"\\xC0\\xFF\".force_encoding('binary')\r\nFile.binwrite('\/tmp\/src.bin', binary_content)\r\n```\r\n\r\n2. Create site.pp\r\n\r\n```\r\n# cat <<END > \/etc\/puppetlabs\/code\/environments\/production\/manifests\/site.pp\r\nfile { '\/tmp\/dst.bin':\r\n  ensure => file,\r\n  content => file('\/tmp\/src.bin'),\r\n}\r\nEND\r\n```\r\n\r\n3. Run the local agent, it will fail as described above depending on the agent and server versions.\r\n\r\n\r\n## Environment\r\n - Puppet7 and 8\r\n\r\n\r\n## Additional Context\r\n\r\nhttps:\/\/github.com\/puppetlabs\/puppet\/pull\/9102\r\nhttps:\/\/puppet.atlassian.net\/browse\/PUP-10096\r\nhttps:\/\/puppetcommunity.slack.com\/archives\/C0W298S9G\/p1707246678595899","comments":[],"labels":["bug","accepted"],"number":9255},{"title":"Thread conflict in Puppet::Pops::Loaders","body":"## Describe the Bug\r\nWe observe the following error across ~5% of all Puppet agent runs in our organization against our Puppet 7.x masters when we set `multithreaded: true`, with any value for `max-active-instances` (even `2`):\r\n\r\n```\r\nERROR [qtp735649759-289] [puppetserver] Puppet Server Error: Evaluation Error: Error while evaluating a Type-Name, Internal Error: Attempt to redefine loader named '<foo> private' (file: \/path\/to\/our\/modules\/foo\/manifests\/init.pp, line: 12, column: 18) on node clientnode.example.com\r\n```\r\n\r\nThe error disappears if we disable threading, or if we hand-insert thread synchronization into the offending method or its caller. It is not consistent to any particular client node, and nodes on which agent runs throw the error will work fine the other ~95% of the time.\r\n\r\nThe source of the error, `add_loader_by_name` in `puppet\/lib\/ruby\/vendor_ruby\/puppet\/pops\/loaders.rb`, is fairly straightforward, adding a new key to an instance variable and throwing the error we observe if the key is already present:\r\n\r\n```\r\n  def add_loader_by_name(loader)\r\n    name = loader.loader_name\r\n    if @loaders_by_name.include?(name)\r\n      raise Puppet::ParseError, _(\"Internal Error: Attempt to redefine loader named '%{name}'\") % { name: name }\r\n    end\r\n    @loaders_by_name[name] = loader\r\n  end\r\n```\r\n\r\nInterestingly, adding `Puppet.info` or `Puppet.warn` output **before** the `if` statement, to debug the call stack and thread state, causes the issue to disappear. I'd theorize that whatever output synchronization the logging system uses adds sort of back-door thread safety. Adding logging **inside** the `if` statement doesn't do this, which makes sense.\r\n\r\nThe calling method in all instances of this error we've logged to date has been `[]`. If we add na\u00efve Ruby-native synchronization to that method as below, our problem disappears:\r\n\r\n```\r\n  def [](loader_name)\r\n    loader = @loaders_by_name[loader_name]\r\n    if loader.nil?\r\n      # Unable to find the module private loader. Try resolving the module\r\n      @my_semaphore.synchronize {\r\n        loader = private_loader_for_module(loader_name[0..-9]) if loader_name.end_with?(' private')\r\n        raise Puppet::ParseError, _(\"Unable to find loader named '%{loader_name}'\") % { loader_name: loader_name } if loader.nil?\r\n      }\r\n    end\r\n    loader\r\n  end\r\n```\r\n\r\nThat's presumably not a correct-for-this-codebase fix by itself, but does point in the general direction of \"it's threads stepping on each other, add a sempahore somewhere.\"\r\n\r\n## Environment\r\n - Puppet Server 7.x (various, up to and including 7.15.0)\r\n - CentOS 7.9.2009, AlmaLinux 8.9\r\n - Sanitized [puppet.conf](https:\/\/github.com\/puppetlabs\/puppet\/files\/14240978\/puppet.conf.txt) and [puppetserver.conf](https:\/\/github.com\/puppetlabs\/puppet\/files\/14240979\/puppetserver.conf.txt) attached\r\n\r\n## Additional Context\r\n\r\nIt's not clear why our ecosystem in particular triggers this issue. While we're a medium-large organization, our Puppet masters are spread around to various regional collections of nodes. The one on which we did the above debugging manages only about a dozen nodes. The issue manifests on all of them.\r\n\r\nOur module ecosystem is old growth forest, with a lot of interwoven dependency. It's possible that the trigger here is multiple references to the same dependent object being resolved in parallel.\r\n\r\nIt's of note that we have a number of modules with names of the form `*_private` (in a search path distinct from our \"main\" module repo). But this seems to occur with any module and does not occur with threading disabled, so is unlikely to be some kind of namespace collision.","comments":["This was originally reported in https:\/\/puppet.atlassian.net\/browse\/PUP-11324. That issue tracker is now read-only, so please continue discussion here.\r\n\r\n","Thanks for letting us know @jstange We currently use the environment object to protect against concurrent access, such as https:\/\/github.com\/puppetlabs\/puppet\/blob\/b04e822d8b4e5bf3caa29d20d19777dbff43fa8b\/lib\/puppet\/pops\/loaders.rb#L28 I think you'd want to do something similar for each of the `Loaders` instance methods that mutate state, like:\r\n\r\n```ruby\r\n def [](loader_name)\r\n   environment.lock.synchronize do\r\n      loader = @loaders_by_name[loader_name]\r\n      if loader.nil?\r\n        # Unable to find the module private loader. Try resolving the module\r\n        loader = private_loader_for_module(loader_name[0..-9]) if loader_name.end_with?(' private')\r\n        raise Puppet::ParseError, _(\"Unable to find loader named '%{loader_name}'\") % { loader_name: loader_name } if loader.nil?\r\n    end\r\n    loader\r\nend\r\n```\r\n\r\nAlternatively you could only lock when `loader.nil?`, but I think you need to relookup again inside the lock (double-checked lock)\r\n\r\n```ruby\r\ndef [](loader_name)\r\n  loader = @loaders_by_name[loader_name]\r\n  if loader.nil?\r\n    environment.lock.synchronize do\r\n     if loader.nil?\r\n       ...\r\n```\r\n\r\nWe don't have any immediate plans for working on this, but we welcome pull requests. I'll put the `help wanted` label on for now.","After some poking I might have some vague idea how threading works in here. Seems like it's JRuby-specific, and in the case I care about it's probably instances of `Puppet::Util::Autoload` that are competing to touch things in parallel.\r\n\r\n`[]` probably isn't the only method that needs a thread seatbelt put on it, but I don't want to blindly add stuff and create potential deadlock conditions. \r\n\r\nI'll spend some time with my stack traces and see if there's anywhere else that looks thread-dangerous and deadlock-safe, wrap those in `environment.lock.synchronize`, and submit a PR of it. Someone who knows what they're doing will have to review- my guesswork about threading in here may be wildly off base."],"labels":["bug","help wanted"],"number":9252},{"title":"Package provider \"pip\" not fully functional with network urls on Ubuntu 22.04","body":"## Describe the Bug\r\nThe `package` provider \"pip\" does not handle correctly the installation of python modules via network urls (e.g. \"git+https:\/\/github.com\/\") on Ubuntu 22.04: this is because on newer `pip` versions the output of `pip freeze --all` (which is used by puppet to test if a python module is already installed) is generated in an unexpected format:\r\n\r\nhttps:\/\/github.com\/puppetlabs\/puppet\/blob\/f9bcd090c28c24d083f77ff0a0723e6d68115466\/lib\/puppet\/provider\/package\/pip.rb#L102-L108\r\n\r\n```shell\r\nroot@831e7bc5baed:\/# lsb_release -a\r\nNo LSB modules are available.\r\nDistributor ID:\tUbuntu\r\nDescription:\tUbuntu 22.04 LTS\r\nRelease:\t22.04\r\nCodename:\tjammy\r\nroot@831e7bc5baed:\/# pip --version\r\npip 22.0.2 from \/usr\/lib\/python3\/dist-packages\/pip (python 3.10)\r\nroot@831e7bc5baed:\/# pip freeze --all | grep -i ^vSphere-Automation-SDK\r\nvsphere-automation-sdk @ git+https:\/\/github.com\/vmware\/vsphere-automation-sdk-python.git@199b26f1d523023927c172afa6f5b2ebb85dd8f9\r\nroot@831e7bc5baed:\/# \r\n```\r\n\r\n On Ubuntu 20.04 this issue does not happen:\r\n\r\n```shell\r\nroot@70b080cc5203:\/# lsb_release -a\r\nNo LSB modules are available.\r\nDistributor ID:\tUbuntu\r\nDescription:\tUbuntu 20.04.6 LTS\r\nRelease:\t20.04\r\nCodename:\tfocal\r\nroot@70b080cc5203:\/# pip --version\r\npip 20.0.2 from \/usr\/lib\/python3\/dist-packages\/pip (python 3.8)\r\nroot@70b080cc5203:\/# pip freeze --all | grep -i ^vSphere-Automation-SDK\r\nvsphere-automation-sdk==1.86.0\r\nroot@70b080cc5203:\/# \r\n```\r\n\r\n## Expected Behavior\r\n`puppet apply` should skip installing the python module when run a second time since it's already installed\r\n\r\n## Steps to Reproduce\r\nFrom an empty Docker container, image `ubuntu:22.04`:\r\n```shell\r\n# install puppet\r\napt update\r\napt install --yes lsb-release wget python3-pip git\r\nwget https:\/\/apt.puppetlabs.com\/puppet8-release-$(lsb_release -sc).deb\r\ndpkg -i puppet8-release-$(lsb_release -sc).deb\r\napt update\r\napt install --yes puppet-agent\r\n\r\n# apply manifest\r\ncat > pip_freeze_issue.pp <<'EOF'\r\npackage { 'vSphere-Automation-SDK':\r\n  ensure   => 'present',\r\n  provider => 'pip',\r\n  source   => 'git+https:\/\/github.com\/vmware\/vsphere-automation-sdk-python.git'\r\n}\r\nEOF\r\n\/opt\/puppetlabs\/bin\/puppet apply pip_freeze_issue.pp\r\n\r\n# check python module\r\npip freeze --all | grep -i ^vSphere-Automation-SDK\r\npip list --format=freeze | grep -i ^vSphere-Automation-SDK\r\n\r\n# apply a second time, should not install the python module again\r\n\/opt\/puppetlabs\/bin\/puppet apply pip_freeze_issue.pp\r\n```\r\n\r\n## Environment\r\n```shell\r\nroot@831e7bc5baed:\/# \/opt\/puppetlabs\/bin\/puppet agent --version\r\n8.4.0\r\nroot@831e7bc5baed:\/# lsb_release -a\r\nNo LSB modules are available.\r\nDistributor ID:\tUbuntu\r\nDescription:\tUbuntu 22.04 LTS\r\nRelease:\t22.04\r\nCodename:\tjammy\r\nroot@831e7bc5baed:\/# \r\n```\r\n\r\n## Additional Context\r\nThe package provider for \"pip\" should use `pip list --format=freeze` instead of `pip freeze --all`, when supported (sorry i don't know the exact version)\r\n","comments":["This should be fixed in https:\/\/github.com\/puppetlabs\/puppet\/pull\/9280","Migrated issue to [PUP-12027](https:\/\/perforce.atlassian.net\/browse\/PUP-12027)"],"labels":["triaged","bug"],"number":9237},{"title":"Private key and client certificate warning messages on a Masterless Puppet Environment","body":"## Describe the Bug\r\nOn a Masterless Puppet Environment using the last version of puppet-agent, we get two warning messages about the fact that there is no private key or certificate, what is expected in this environment. \r\nThe `puppet-agent-7.16.0-1.el9.x86_64` is the most recent version that does not show the warning, from version `puppet-agent-7.17.0-1.el9.x86_64` the warnings are displayed.\r\nCan you please take a look?\r\n\r\n## Expected Behavior\r\nNo warning messages on a Masterless Puppet Environment.\r\n\r\n## Steps to Reproduce\r\nIt's a bug with the file resource https:\/\/www.puppet.com\/docs\/puppet\/5.5\/types\/file.html\r\n\r\n```\r\n# mkdir -p testing\/filebug\/manifests\r\n# vi testing\/filebug\/manifests\/init.pp\r\n# cat testing\/filebug\/manifests\/init.pp \r\nclass filebug {\r\n\r\n  $test_file = 'https:\/\/link.testfile.org\/PDF10MB'\r\n\r\n  file { '\/tmp\/test_file':\r\n    ensure  => 'file',\r\n    source  => $test_file,\r\n  }\r\n}\r\n# puppet apply --modulepath=\/root\/testing -e \"include filebug\" \r\nNotice: Compiled catalog for testhost.cern.ch in environment production in 0.01 seconds\r\nWarning: Private key for \u2018testhost.cern.ch' does not exist\r\nWarning: Client certificate for \u2018testhost.cern.ch' does not exist\r\nNotice: \/Stage[main]\/Filebug\/File[\/tmp\/test_file]\/ensure: defined content as '{mtime}2022-10-08 01:39:09 UTC'\r\nNotice: Applied catalog in 4.88 seconds\r\n# rpm -qa puppet-agent\r\npuppet-agent-7.28.0-1.el9.x86_64\r\n```\r\n\r\n\r\n## Environment\r\n - puppet-agent-7.28.0-1.el9.x86_64\r\n - RHEL8\/9 and AlmaLinux8\/9\r\n","comments":["The agent assumes its private key and client cert are available so that it can use them to establish a mTLS connection to the `source`. It should be more defensive in case we're running in masterless and don't have a client cert. There's a related but different issue https:\/\/puppet.atlassian.net\/browse\/PUP-11331"],"labels":["bug"],"number":9248},{"title":"Misleading warning when fact values limit is exceeded","body":"## Describe the Bug\r\n\r\nPuppet agents print a warning if the number of fact **values** exceeds its soft limit:\r\n\r\n```Warning: The current total number of facts: 5787 exceeds the number of facts limit: 2048```\r\n\r\nHowever, the wording \"total number of facts\" is confusing, because it sounds like it's the number of facts, when really the problem is the number of values that the facts are producing, due to nested arrays and hashes like the `_puppet_inventory_1` fact in PE.\r\n\r\n## Expected Behavior\r\n\r\nThe message should say something like\r\n\r\n```The total number of fact values X exceeds the fact values limit Y```\r\n\r\nSee https:\/\/puppetcommunity.slack.com\/archives\/CFD8Z9A4T\/p1705430272043379?thread_ts=1705428680.188929&cid=CFD8Z9A4T\r\n\r\nThe documentation for the [`number_of_facts_soft_limit`](https:\/\/github.com\/puppetlabs\/puppet\/blob\/3192f4aab419b221402f738ed1be90de0d969be5\/lib\/puppet\/defaults.rb#L1805-L1808C58) should be updated so its clear we're counting the leaves of structured facts.\r\n\r\n## Steps to Reproduce\r\nSteps to reproduce the behavior:\r\n\r\n```\r\n# cat <<END > \/opt\/puppetlabs\/facter\/facts.d\/many.rb \r\n#!\/opt\/puppetlabs\/puppet\/bin\/ruby\r\nrequire 'json'\r\nputs JSON.dump(\"many\" => [*1..3000])\r\nEND\r\n# puppet agent -t\r\n\/opt\/puppetlabs\/puppet\/bin\/puppet agent -t\r\nInfo: Using environment 'production'\r\nInfo: Retrieving pluginfacts\r\nInfo: Retrieving plugin\r\nWarning: The current total number of facts: 3323 exceeds the number of facts limit: 2048\r\n```\r\n\r\n## Environment\r\n - Version 8.4.0 and 7.28.0\r\n\r\n## Additional Context\r\n\r\nThis behavior is occurring because we corrected how fact values are counted, see https:\/\/github.com\/puppetlabs\/puppet\/commit\/f33de2438890c46c266c96155250260e411a4d34","comments":[],"labels":["bug","help wanted"],"number":9226},{"title":"Long delay when printing catalog server in Puppet 7.28.0 on IPv6-only clients","body":"## Describe the Bug\r\n\r\nWhen running Puppet agent 7.28 interactively (e.g. `puppet agent --test --noop`) on a host with an IPv6 address but without an IPv4 address, the run consistently hangs for over two minutes after printing `Info: Loading facts` and before printing `Notice: Requesting catalog from puppet.example.com:8140`.\r\n\r\nWhen running on a dual stack host with both IPv4 and IPv6 addresses, there is no pause and the `Notice` includes an IPv4 address in parentheses: `Notice: Requesting catalog from puppet.example.com:8140 (10.0.0.1)`.\r\n\r\n## Expected Behavior\r\nThere should be no delay when running Puppet on hosts with only an IPv6 address.\r\n\r\n## Steps to Reproduce\r\nOn an IPv6 only host that uses a Puppet server with both IPv4 and IPv6 addresses, run `puppet agent --test --noop`.\r\n\r\n## Environment\r\n - Version 7.28.0\r\n - Platform Debian Bullseye\r\n\r\n## Additional Context\r\nThe Puppet server is dual stack with routable IPv4 and IPv6 addresses. These are in DNS and can be resolved from the client system using the system resolver as normal.\r\n\r\nThis delay was not present in previous versions of Puppet. Reverting Puppet agent to 7.27.0 resolves the problem.\r\n\r\nLooking at [puppetlabs\/puppet#9126](https:\/\/github.com\/puppetlabs\/puppet\/pull\/9126), it appears that [the lookup using\u00a0`Resolv.getaddress`](https:\/\/github.com\/puppetlabs\/puppet\/pull\/9126\/files#diff-7137e229af0fe05ca6b5d85eacb04c666fc8ab11329c32b8b888e9ddbba753c1R18)is causing the delay.\r\n\r\nPlease note that all hostnames and IP addresses have been redacted and replaced in the examples below, but otherwise they are reproduced exactly as we ran them.\r\n\r\nUsing Ruby 2.7.8 on a dual stack host:\r\n```\r\n$ ruby --version; time ruby -r resolv -e 'puts Resolv.getaddress(\"puppet.example.com\")'\r\nruby 2.7.8p225 (2023-03-30 revision 1f4d455848) [x86_64-linux]\r\n10.0.0.1\r\n\r\nreal\t0m0.162s\r\nuser\t0m0.137s\r\nsys\t0m0.024s\r\n```\r\nUsing Ruby 2.7.8 on an IPv6 only host:\r\n```\r\n$ ruby --version; time ruby -r resolv -e 'puts Resolv.getaddress(\"puppet.example.com\")'\r\nruby 2.7.8p225 (2023-03-30 revision 1f4d455848) [x86_64-linux]\r\nTraceback (most recent call last):\r\n\t2: from -e:1:in `<main>'\r\n\t1: from \/opt\/rbenv\/versions\/2.7.8\/lib\/ruby\/2.7.0\/resolv.rb:44:in `getaddress'\r\n\/opt\/rbenv\/versions\/2.7.8\/lib\/ruby\/2.7.0\/resolv.rb:94:in `getaddress': no address for puppet.example.com (Resolv::ResolvError)\r\n\r\nreal\t2m40.428s\r\nuser\t0m0.182s\r\nsys\t0m0.056s\r\n```\r\nUsing Ruby 3.2.2 on an IPv6 only host _does_ return a result, but it's an IPv4 address which is arguably not what you would expect, so I suspect this issue is less visible in Puppet 8.x but may represent a related but slightly different bug:\r\n```\r\n$ ruby --version; time ruby -r resolv -e 'puts Resolv.getaddress(\"puppet.example.com\")'\r\nruby 3.2.2 (2023-03-30 revision e51014f9c0) [x86_64-linux]\r\n10.0.0.1\r\n\r\nreal\t0m0.191s\r\nuser\t0m0.152s\r\nsys\t0m0.039s\r\n```\r\nNoting that if you use the [`Resolv` gem](https:\/\/stdgems.org\/resolv\/) under Ruby 2.7.8 rather than the builtin, this works as per 3.2.2 which would seem to be what you'd expect:\r\n```\r\n$ cat Gemfile; ruby --version; time ruby -r 'bundler\/setup' -r resolv -e 'puts Resolv.getaddress(\"puppet.example.com\")'\r\nsource \"https:\/\/rubygems.org\"\r\ngem \"resolv\", \"0.3.0\"\r\nruby 2.7.8p225 (2023-03-30 revision 1f4d455848) [x86_64-linux]\r\n10.0.0.1\r\n\r\nreal\t0m0.328s\r\nuser\t0m0.296s\r\nsys\t0m0.031s\r\n```\r\n","comments":["Thanks for letting us know @sagepe. Are you able to provide the steps you used to disable IPv4 on a dual stack machine so we can try to reproduce this? Also the output of `facter networking` would be helpful.","> Are you able to provide the steps you used to disable IPv4 on a dual stack machine so we can try to reproduce this?\r\n\r\nI just provision one in our infra, so I don't manually make the changes. It's a bit tricky to provide definitive instructions as it will of course vary depending on how the server instances are provisioned, the OS family, etc.\r\n\r\nOur IPv6 only systems do have an IPv4 loopback, but no IPv4 address on their public interfaces. They have an IPv6 loopback address, a single global public IPv6 address and a link-local IPv6 address - see the facter output; I've redacted the actual addresses and hostnames:\r\n\r\n[ipv6only.networking.facts.txt](https:\/\/github.com\/puppetlabs\/puppet\/files\/14138273\/ipv6only.networking.facts.txt)\r\n\r\nIf you're starting point is a dual stack system with both IPv4 and IPv6 addresses, you may be able to replicate it with a `\/etc\/network\/interfaces` file that looks something like the below; you'll also need to ensure that you have functioning IPv6 DNS resolvers configured in `\/etc\/resolv.conf` and no automation that will attempt to override\/revert things (including a DHCP service or systemd of any of the other things that might think it knows better).\r\n\r\n```\r\nauto lo\r\niface lo inet loopback\r\n\r\nauto eth0\r\niface eth0 inet6 static\r\n    address <YOUR IPv6 address>\r\n```\r\n","Migrated issue to [PUP-12022](https:\/\/perforce.atlassian.net\/browse\/PUP-12022)"],"labels":["triaged","bug"],"number":9223},{"title":"Environment names can't contain only integer","body":"## Describe the Bug\r\nUsing an environment name composed only of numeric characters makes the catalog compilation fail.\r\nThe [puppet documentation](https:\/\/www.puppet.com\/docs\/puppet\/8\/lang_reserved.html#lang_acceptable_char-environment-names) explains that environment names can contain lowercase letters, numbers and underscores. It does not prohibit the use of numeric characters only.\r\n\r\nWhen using an environment like `42`, we get ruby stacktrace like this one:\r\n\r\n```syslog\r\n2024-01-23T11:02:48.938+01:00 ERROR [qtp472974372-11877] [puppetserver] Puppet Server Error: undefined method `match' for 42:Integer\r\n\/opt\/puppetlabs\/puppet\/lib\/ruby\/vendor_ruby\/puppet\/node\/environment.rb:127:in `valid_name?'\r\n\/opt\/puppetlabs\/puppet\/lib\/ruby\/vendor_ruby\/puppet\/network\/http\/api\/indirected_routes.rb:90:in `uri2indirection'\r\n\/opt\/puppetlabs\/puppet\/lib\/ruby\/vendor_ruby\/puppet\/network\/http\/api\/indirected_routes.rb:35:in `call'\r\n\/opt\/puppetlabs\/puppet\/lib\/ruby\/vendor_ruby\/puppet\/network\/http\/api\/server\/v3.rb:17:in `block in wrap'\r\n\/opt\/puppetlabs\/puppet\/lib\/ruby\/vendor_ruby\/puppet\/network\/http\/route.rb:82:in `block in process'\r\norg\/jruby\/RubyArray.java:1865:in `each'\r\n\/opt\/puppetlabs\/puppet\/lib\/ruby\/vendor_ruby\/puppet\/network\/http\/route.rb:81:in `process'\r\n\/opt\/puppetlabs\/puppet\/lib\/ruby\/vendor_ruby\/puppet\/network\/http\/route.rb:88:in `process'\r\n\/opt\/puppetlabs\/puppet\/lib\/ruby\/vendor_ruby\/puppet\/network\/http\/route.rb:88:in `process'\r\n\/opt\/puppetlabs\/puppet\/lib\/ruby\/vendor_ruby\/puppet\/network\/http\/handler.rb:86:in `block in process'\r\n\/opt\/puppetlabs\/puppet\/lib\/ruby\/vendor_ruby\/puppet\/network\/http\/handler.rb:69:in `block in with_request_profiling'\r\n\/opt\/puppetlabs\/puppet\/lib\/ruby\/vendor_ruby\/puppet\/util\/profiler\/around_profiler.rb:58:in `profile'\r\n\/opt\/puppetlabs\/puppet\/lib\/ruby\/vendor_ruby\/puppet\/util\/profiler.rb:51:in `profile'\r\n\/opt\/puppetlabs\/puppet\/lib\/ruby\/vendor_ruby\/puppet\/network\/http\/handler.rb:65:in `with_request_profiling'\r\n\/opt\/puppetlabs\/puppet\/lib\/ruby\/vendor_ruby\/puppet\/network\/http\/handler.rb:85:in `block in process'\r\n\/opt\/puppetlabs\/puppet\/lib\/ruby\/vendor_ruby\/puppet\/network\/http\/handler.rb:92:in `respond_to_errors'\r\n\/opt\/puppetlabs\/puppet\/lib\/ruby\/vendor_ruby\/puppet\/network\/http\/handler.rb:84:in `process'\r\nuri:classloader:\/puppetserver-lib\/puppet\/server\/master.rb:69:in `block in handleRequest'\r\n\/opt\/puppetlabs\/puppet\/lib\/ruby\/vendor_ruby\/puppet\/context.rb:62:in `override'\r\n\/opt\/puppetlabs\/puppet\/lib\/ruby\/vendor_ruby\/puppet.rb:289:in `override'\r\nuri:classloader:\/puppetserver-lib\/puppet\/server\/master.rb:68:in `handleRequest'\r\n```\r\n \r\n \r\n## Expected Behavior\r\nAn environment name composed only of numeric characters should be valid.\r\n\r\n## Steps to Reproduce\r\nSteps to reproduce the behavior:\r\n1. Create a puppet environment with only numeric characters (eg.: 42)\r\n2. run `puppet agent -t --environment 42`\r\n3. get the error described above on the puppetserver.\r\n\r\n## Environment\r\n - puppetserver Version 7.14.0-1buster\r\n - Platform Debian buster\r\n\r\n## Additional Context\r\nWe are deploying environments from a Gitlab repository with r10k.\r\n[GitLab uses the default pattern `%{id}-%{title}` when creating a branch from an issue](https:\/\/docs.gitlab.com\/ee\/user\/project\/repository\/branches\/#configure-default-pattern-for-branch-names-from-issues).\r\nIf we want keep branch names equals to environment names (i.e. without hyphens), the easy solution is to replace the pattern with `%{id}` only. Otherwise the spaces and special characters in `%{title}` xould be converted to hyphens.\r\n\r\nUsing this workflows, we end up with some numeric only branches\/puppet environments. \r\n\r\nAccording to puppet documentation, this shouldn't have been a problem.\r\n\r\nA pull-request to fix this in on the way.","comments":[],"labels":["bug"],"number":9220}]