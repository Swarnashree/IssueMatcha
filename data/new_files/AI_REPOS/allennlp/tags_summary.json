[{"issue_title": "AllenNLP biased towards BERT", "tags": ["NLP", "PyTorch", "Deep Learning", "Natural Language Processing", "AllenNLP", "BERT", "RoBERTa", "Transformers", "Named Entity Recognition", "HuggingFace", "Optuna", "Hyperparameter Optimization", "Python 3.8", "DataGridSearch", "Conll2003", "Issue", "Bug Report"], "summary": "AllenNLP is an Apache 2.0 NLP research library, built on PyTorch, for developing state-of-the-art deep learning models on a wide variety of linguistic tasks. It is now in maintenance mode and will not be adding new features or upgrading dependencies. The library provides a data processing module, a collection of PyTorch modules for text, functionality for training models, and a suite of tools for fairness and interpretability. AllenNLP requires Python 3.6.1 or later and PyTorch. It can be installed via conda-forge, pip, or Docker. The repository also includes a collection of officially supported models and plugins."}, {"issue_title": "Computing rouge is significantly slow", "tags": ["Natural Language Processing", "PyTorch", "Deep Learning", "NLP Research", "AllenNLP", "Bug Report", "Computational Linguistics", "Python", "Open Source", "Language Modeling", "Text Analysis", "NLP Toolkit", "NLP Library", "NLP Model Training", "NLP Evaluation", "NLP Prediction", "NLP Data Processing"], "summary": "AllenNLP is an Apache 2.0 NLP research library, built on PyTorch, for developing state-of-the-art deep learning models on a wide variety of linguistic tasks. It is now in maintenance mode and will not be adding new features or upgrading dependencies. The library provides a data processing module, a collection of PyTorch modules for text, functionality for training models, and a suite of tools for fairness and interpretability. AllenNLP requires Python 3.6.1 or later and PyTorch. It can be installed via conda-forge, pip, or Docker. The repository also includes a collection of officially supported models and plugins."}, {"issue_title": "structured-prediction-constituency-parser adds extra spaces", "tags": ["Natural Language Processing", "PyTorch", "Deep Learning", "Research Library", "Constituency Parser", "Spacy", "Tokenizer", "Penn Tree Bank", "Hyperparameter Optimization", "Optuna", "AI2 Tango", "Transformers", "Pretrained Models", "Experiment Management", "Configuration Language", "Trainer", "AllenNLP Models", "Documentation", "Guides", "Gallery", "Demo", "Continuous Integration", "Nightly Releases", "Python 3.6.1+"], "summary": "AllenNLP is an Apache 2.0 NLP research library, built on PyTorch, for developing state-of-the-art deep learning models on a wide variety of linguistic tasks. It is now in maintenance mode and will not be adding new features or upgrading dependencies. The library provides a data processing module, a collection of PyTorch modules for text, functionality for training models, and a suite of tools for fairness and interpretability. AllenNLP requires Python 3.6.1 or later and PyTorch. It can be installed via conda-forge, pip, or Docker. The repository also includes a collection of officially supported models and plugins."}, {"issue_title": "Windows", "tags": ["Natural Language Processing", "PyTorch", "Apache 2.0", "Research Library", "Deep Learning", "Allen Institute", "AI", "Python", "Open Source", "NLP Models", "Data Processing", "Text Analysis", "Machine Learning", "Natural Language Understanding", "Natural Language Generation"], "summary": "AllenNLP is an Apache 2.0 NLP research library, built on PyTorch, for developing state-of-the-art deep learning models on a wide variety of linguistic tasks. It is now in maintenance mode, with no new features or upgraded dependencies being added. The library provides a collection of PyTorch modules for use with text, tensor utility functions, and functionality for training models. AllenNLP requires Python 3.6.1 or later and PyTorch, and is available for installation via conda-forge, pip, or Docker. The library has been used in over 1000 research projects and has a wide range of plugins and officially supported models."}, {"issue_title": "Why not add transformer tokens to vocabulary in init phrase", "tags": ["PyTorch", "NLP", "deep learning", "research library", "AllenNLP", "Apache 2.0", "open source", "AI2", "maintenance mode", "alternatives suggested", "trainer", "configuration language", "experiment management", "modules", "nn package", "framework", "Fairness", "Interpret", "vectorization", "transformers library", "plugins", "maintainer", "community"], "name": "AllenNLP", "description": "An Apache 2.0 NLP research library, built on PyTorch, for developing state-of-the-art deep learning models on a wide variety of linguistic tasks.", "url": "https://github.com/allenai/allennlp", "keywords": ["NLP", "natural-language-processing", "deep-learning", "pytorch"], "license": "Apache-2.0", "repository": {"type": "git", "url": "git+https://github.com/allenai/allennlp.git"}, "author": {"name": "Allen Institute for Artificial Intelligence"}, "maintainers": [{"name": "allenai", "email": "info@allenai.org", "url": "https://allenai.org/"}]}]