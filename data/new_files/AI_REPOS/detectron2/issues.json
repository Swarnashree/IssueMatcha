[{"title":"Adjusting Model Confidence Level","body":"it's possible to adjust a model's confidence level because i unable to obtain the complete labeled coordinates along with the corresponding text\r\n","comments":[],"labels":["documentation"],"number":5238},{"title":"Training steps automation ","body":"Just like yolov8 is it possible for detectron2 to automate and export perfectly trained steps , As of now we are required to provide number of steps check for detection if not found train again , In yolov8 you just pass on the batch size and the training starts and it exports optimum model by checking validation loss . ","comments":[],"labels":["enhancement"],"number":5236},{"title":"Use `torch.amax` instead of `torch.max`","body":"In torch 1.12.1, torch.max(input, dim, ...) operation on cpu causes unintended cpu overhead which is not the case for torch.amax.","comments":["Hi @seongmoon729! \n\nThank you for your pull request and welcome to our community. \n\n# Action Required\n\nIn order to merge **any pull request** (code, docs, etc.), we **require** contributors to sign our **Contributor License Agreement**, and we don't seem to have one on file for you.\n\n# Process\n\nIn order for us to review and merge your suggested changes, please sign at <https:\/\/code.facebook.com\/cla>. **If you are contributing on behalf of someone else (eg your employer)**, the individual CLA may not be sufficient and your employer may need to sign the corporate CLA.\n\nOnce the CLA is signed, our tooling will perform checks and validations. Afterwards, the **pull request will be tagged** with `CLA signed`. The tagging process may take up to 1 hour after signing. Please give it that time before contacting us about it.\n\nIf you have received this in error or have any questions, please contact us at [cla@meta.com](mailto:cla@meta.com?subject=CLA%20for%20facebookresearch%2Fdetectron2%20%235224). Thanks!"],"labels":["CLA Signed"],"number":5224},{"title":"refactor create local process group code for distributed training in \"detectron2\/utils\/comm.py\"","body":"## \ud83d\ude80 Feature\r\nIn \"detectron2\/utils\/comm.py\", there is a function that name is \"create_local_process_group\".\r\nThe funciton is bellow:\r\n```python\r\n@functools.lru_cache()\r\ndef create_local_process_group(num_workers_per_machine: int) -> None:\r\n    \"\"\"\r\n    Create a process group that contains ranks within the same machine.\r\n\r\n    Detectron2's launch() in engine\/launch.py will call this function. If you start\r\n    workers without launch(), you'll have to also call this. Otherwise utilities\r\n    like `get_local_rank()` will not work.\r\n\r\n    This function contains a barrier. All processes must call it together.\r\n\r\n    Args:\r\n        num_workers_per_machine: the number of worker processes per machine. Typically\r\n          the number of GPUs.\r\n    \"\"\"\r\n    global _LOCAL_PROCESS_GROUP\r\n    assert _LOCAL_PROCESS_GROUP is None\r\n    assert get_world_size() % num_workers_per_machine == 0\r\n    num_machines = get_world_size() \/\/ num_workers_per_machine\r\n    machine_rank = get_rank() \/\/ num_workers_per_machine\r\n    for i in range(num_machines):\r\n        ranks_on_i = list(range(i * num_workers_per_machine, (i + 1) * num_workers_per_machine))\r\n        pg = dist.new_group(ranks_on_i)\r\n        if i == machine_rank:\r\n            _LOCAL_PROCESS_GROUP = pg\r\n```\r\nI think the function is create dist.new_group, and set LOCAL_PROGRESS_GROUP according to machine_rank.\r\nSo they create some useless pg that i is not equal machine_rank\r\n\r\n## Motivation & Examples\r\nI think the function may need refactor like bellow:\r\n```python\r\n@functools.lru_cache()\r\ndef create_local_process_group(num_workers_per_machine: int) -> None:\r\n    global _LOCAL_PROCESS_GROUP\r\n    assert _LOCAL_PROCESS_GROUP is None\r\n    assert get_world_size() % num_workers_per_machine == 0\r\n    num_machines = get_world_size() \/\/ num_workers_per_machine\r\n    machine_rank = get_rank() \/\/ num_workers_per_machine\r\n    for i in range(num_machines):\r\n        if i == machine_rank:\r\n            ranks_on_i = list(range(i * num_workers_per_machine, (i + 1) * num_workers_per_machine))\r\n            pg = dist.new_group(ranks_on_i)\r\n            _LOCAL_PROCESS_GROUP = pg\r\n```\r\n\r\n","comments":["Your suggestion doesn't follow the requirement of pytorch's `dist.new_group`: \r\n\r\n![image](https:\/\/github.com\/facebookresearch\/detectron2\/assets\/1381301\/82573876-cf13-493b-bffd-153936aff7ab)\r\n"],"labels":["enhancement"],"number":5202},{"title":"Creating your own custom pretraining weights .pkl for Aerial Imagery with Detectron2","body":"Hello all , As per available pretrained nets which were trained on msra dataset or coco dataset and we have various versions of resnet50 ,101 and 152 . I was planning go ahead with resnet101 as we train it or fine tune it using existing .pkl , i want to create my own .pkl for further training to simplify like create my massive aerial imagery dataset and train it on top of coco dataset so it would have learned features of earlier and now new aerial features than use it for further training of which we create .pth file .\r\nI tried convert .pth file to .pkl using script  convert-torchvision-to-d2.py available in d2 tools folder however it could not be converted so i changed line `newmodel[k] = obj.pop(old_k).detach().numpy()` to `newmodel[k] = obj.pop(old_k)` it got converted however gave error when used for training . Please help me out thank you !","comments":[],"labels":["enhancement"],"number":5189}]