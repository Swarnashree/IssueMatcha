[{"title":"DOC: undocumented behavior for converting month timedelta64 to days","body":"### Issue with current documentation:\r\n\r\nI have three syntaxes that attempt to convert a timedelta64 in month into days. As is well explained in the documentation:\r\nhttps:\/\/numpy.org\/doc\/stable\/reference\/arrays.datetime.html#arrays-datetime\r\nthis is not possible because we  do not know how many days a month holds:\r\n\r\n`np.timedelta64(1, 'M') \/ np.timedelta64(1, 'D')`\r\n`Cannot get a common metadata divisor for Numpy datetime metadata [M] and [D] because they have incompatible nonlinear base time units.`\r\n\r\n`timedelta64(timedelta64(1, 'M'), 'D')`\r\n`Cannot cast NumPy timedelta64 scalar from metadata [M] to [D] according to the rule 'same_kind'`\r\n\r\nbut this yields:\r\n\r\n`timedelta64(1, 'M').astype(timedelta64(1, 'D'))`\r\n`numpy.timedelta64(30,'D')`\r\n\r\nI am surprised that there is no error in the latter case but I am mostly interested to find out which rules are used to determine 30 in this case. For example:\r\n\r\n`timedelta64(3, 'M').astype(timedelta64(1, 'D'))`\r\n`numpy.timedelta64(91,'D')`\r\n\r\nwhich indicates to me that there is some kind of heuristics used but I have not been able to find its documentation.\r\n\r\nThank you for your help,\r\n\r\nSacha\r\n\r\n### Idea or request for content:\r\n\r\n_No response_","comments":[],"labels":["04 - Documentation"],"number":26121},{"title":"ENH: Clarify error message for invalid array indices","body":"This enhancement updates the error message thrown during array indexing\r\nwith invalid objects. Previously, the message did not explicitly mention\r\nthat tuples of valid indexing objects are also acceptable. This could lead\r\nto confusion, especially when debugging legacy code or for users less\r\nfamiliar with NumPy's indexing rules.\r\n\r\nThe new error message now includes \"tuples of these objects\" to clearly\r\nindicate that tuples containing any combination of valid indices (integers,\r\nslices, ellipsis, numpy.newaxis, and integer or boolean arrays) are valid\r\nindexing methods. This change aims to reduce misunderstanding and improve\r\nthe developer experience by providing more direct guidance on valid\r\nindexing types.\r\n\r\nSee ticket #26115","comments":[],"labels":["01 - Enhancement"],"number":26120},{"title":"ENH: inherit numerical dtypes from abstract ones.","body":"I couldn't quite stand how we are working around not having abstract dtypes by adding weird promotors in #26105, so thought one should just make them, especially since (as I found out) all the basic infrastructure is there.\r\n\r\nSo, this let's all numerical legacy dtypes inherit from the abstract types defined for python `int`, `float` and `complex`. This follows what was mentioned to be the plan all along in the comments in `abstractdtype`, though it does not yet change the names throughout, since I wanted to be sure first I'm not barking up the wrong tree (it took the better part of the day already, mostly to realize that the abstract dtypes better inherit from `PyArrayDescr_Type`, otherwise nothing works).\r\n\r\nAnyway, with this, the `StringDType` multiplication promotors are now their logical selves, the work-around can be removed, and everything works.","comments":["Nice! Thank you for taking this on. I wanted to but have several other things that are higher priority, in particular opening at least a WIP PR for pandas with benchmarks. I'll try to look over this on Monday if I don't get to it sooner.\r\n\r\nOne thought: might it make sense to define an abstract python string dtype? There are a number of spots it makes sense to define promoters for both bytes and unicode in stringdtype, and third-party libraries might want to write promoters for bytes, unicode, and stringdtype all in one go.","> One thought: might it make sense to define an abstract python string dtype? There are a number of spots it makes sense to define promoters for both bytes and unicode in stringdtype, and third-party libraries might want to write promoters for bytes, unicode, and stringdtype all in one go.\r\n\r\nCertainly for 'U' and 'T', which can just be `PyArray_PyStrAbstractDType` (using the current name; really should just delete the \"Py\" part, I think!). Though definitely in a separate PR!","Nice, there is a wrinkle however that I have to think about:  At this point we are using these dtypes also as pretty much concrete ones in the ufunc machinery.  I.e. we have loops registered that must *only* match Python integers.\r\nSo, while this *was* my original intention always, it clashes with those loops, because with this we have to find a new way make a distinction so that they don't match all integer arrays!\r\nThat might be a second `AnyInt` of which `PyInt` is a subclass (they can be basically the same thing I guess), or maybe we have another idea on the ufunc side?\r\n(E.g. only these are special, if we avoid `->abstract` checks in the lookup, we could maybe even register them with `int` as a type.)\r\n\r\nBecause of that I was wondering about creating a general factory for abstract DTypes where you can `DType.register()` (like a Python ABC).\r\nUnfortunately it is *not* possible to create a subclass of ABCMeta because it has a `__new__`, but C-extension metaclasses don't support `__new__` (you can *only* have factories), that is restriction may be partiall my fault, but it is also just the truth: ABCMeta `__new__` would not be called!  (I actually wanted a way to do this, but I don't think Python has it yet.)\r\n\r\nSo, you can do it, but if you don't want to do C-side monkey-patching to live in a future that doesn't even exist in Python dev yet, you basically have to roll a minimal ABCMeta implementation or copy the Python one.","Aha, I initially thought that this doesn't cause problems yet, but it actually does:\r\n```\r\na = np.ones(10000, dtype=np.int64)\r\nb = np.ones(10000, dtype=np.int32)\r\n%timeit a == b\r\n```\r\nis more than 10x slower in the current setup because it is promoted to `O,O->?` rather than `int64,int64->?`.\r\n\r\nOn the plus side, at least that gives us a clear example of what we are dealing with.  Thoughs:\r\n* The pyint->object promoter *could* be a loop also not a promoter (maybe slightly tedious but not a big deal).  That only helps if either:\r\n  1. matching behavior differs for promoters vs. arraymethods.\r\n  2. that loop needs to truly deal with all combinations (we still have the option to \"normalize\" away a python integer here for a loop that doesn't implement the scalar special path).\r\n* (additionally to 2. above, I think) we can probably say that the promoter is just wrong, it should just do the right promotion for *any* integer dtype, or maybe it needs the `matches` return capability from the other PR to say that it really only cares about the actual python scalars.\r\n\r\nNone of that seems quite ideal, although, if we accept the \"dual\" meaning slighty maybe the setup is pretty decent as it is.  We may want the \"matches\" and we probably want that point 2., but with that it seems we can tweak things enough that the exact scalar match doable, but you don't have to worry about it normally.\r\n\r\n---\r\n\r\n**EDIT: I should say that the changes here are great and all look good!  The only issue is this subtle problem of \"dual use\" when registering vs. what is passed in as the loop DType.**","I've also been looking at consequences, but started with `StringDType` itself. There, `PyArray_PyIntAbstractDType` was actually used as the catch-all for general integers for `find`, `startswith`, and `replace` (and reverse\/similar versions), so those don't work with numpy ints or arrays in current master, but do work with this PR - I added some tests that now succeed.","I need to think a bit about the equality example - would some of this be solved by your earlier suggestion, of the python int being its own \"`PyArray_PyIntDType`\" dtype that also inherits from `PyArray_IntAbstractDType`?","> of the python int being its own \"PyArray_PyIntDType\" dtype that also inherits from PyArray_IntAbstractDType?\r\n\r\nYes, it would solve this (either with or without also inheriting).  We could make that part a fallback like the reduction case: if nothing was found for it, `PyIntDType` is promoted to the default integer and we try again.","> OK, by going through all places where NPY_DT_is_abstract was used, I found the two where really that was just a short-cut for \"could be python scalar\"\r\n\r\nSorry for not getting back earlier:  That sounds fine, I was considering that they maybe shouldn't be marked \"abstract\".  In a sense they still are, as you say, they don't have any instance you can attach to an array.\r\nI think renaming them is fine, we don't have to talk about abstract vs. not abstract TBH for now.  To some degree maybe we don't even need the distinction (I think I had used it for common-dtype logic, but somehow it didn't turn out helpful).  In other words it migth make more sense to use it only for \"only has subclasses that are attachable\".\r\n\r\n> Also, I think it would still be good to have this in 2.0\r\n\r\nYes, I tend to agree: it should have no user-facing changes, but could be significant enough help for dtypes.\r\n\r\n> Note that there is a comment in the file that there is only one free slot, so if we need to expose all 6, then I need some help in how to adjust things\r\n\r\nAck...  that is annoying.  Actually, I think we can just place them in the normal table the same as:\r\n```\r\n    'PyArrayDescr_Type':                (3, \"PyArray_DTypeMeta\"),\r\n```\r\nIn principle the other ones could be \"moved\" over also, but that block is not bad there either.\r\n\r\n---\r\n\r\nAnyway, will have to look closer at it soon, but thanks a lot for looking into this, I had gotten a bit lost in having some that support `.register()`, etc. but this solves a lot and is much simpler.  "],"labels":["01 - Enhancement","component: numpy.dtype"],"number":26116},{"title":"BUG: Exception text when slicing with an invalid object does not report tuple as an option","body":"### Describe the issue:\n\nWhen slicing an array with an invalid object, like a list, the exception text is:\r\n\r\n\"IndexError: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices\"\r\n\r\nwhich is generated on line 606 of _core\/src\/multiarray\/mapping.c.\r\n\r\nThis was appropriate when lists of indices were accepted or detected as deprecated, but is misleading now. Would it be better to report something like the following:\r\n\r\nIndexError: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`), **tuples of these objects**, and integer or boolean arrays are valid indices\n\n### Reproduce the code example:\n\n```python\nimport numpy\r\n\r\nmyarray = numpy.zeros((5,5))\r\n\r\n# generates misleading exception\r\nslice = myarray[[slice(None),slice(None)]]\r\n\r\n# correct\r\nslice = myarray[(slice(None),slice(None))]\n```\n\n\n### Error message:\n\n```shell\nIndexError: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices\n```\n\n\n### Python and NumPy Versions:\n\nPython version: all\r\n\r\nNumpy version: all up to current main branch (commit 20185fd).\r\n\r\n\n\n### Runtime Environment:\n\n_No response_\n\n### Context for the issue:\n\nSeeing the exception, especially debugging legacy code that uses lists of slices, it's easy to waste time checking the individual indices, rather than the acutal indexing object.","comments":[],"labels":["00 - Bug"],"number":26115},{"title":"BLD: Do not use -O3 flag when building in debug mode","body":"Dispatch sources currently get built with -O3 even in debug mode which made debugging in gdb hard. \r\n\r\n<!--         ----------------------------------------------------------------\r\n                MAKE SURE YOUR PR GETS THE ATTENTION IT DESERVES!\r\n                ----------------------------------------------------------------\r\n\r\n*  FORMAT IT RIGHT:\r\n      https:\/\/www.numpy.org\/devdocs\/dev\/development_workflow.html#writing-the-commit-message\r\n\r\n*  IF IT'S A NEW FEATURE OR API CHANGE, TEST THE WATERS:\r\n      https:\/\/www.numpy.org\/devdocs\/dev\/development_workflow.html#get-the-mailing-list-s-opinion\r\n\r\n*  HIT ALL THE GUIDELINES:\r\n      https:\/\/numpy.org\/devdocs\/dev\/index.html#guidelines\r\n\r\n*  WHAT TO DO IF WE HAVEN'T GOTTEN BACK TO YOU:\r\n      https:\/\/www.numpy.org\/devdocs\/dev\/development_workflow.html#getting-your-pr-reviewed\r\n-->\r\n","comments":[],"labels":["16 - Development","36 - Build"],"number":26113}]